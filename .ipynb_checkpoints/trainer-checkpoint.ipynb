{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required python standard libraries\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All torch related imports \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms\n",
    "from torch import nn, optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cv2 to read an image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All sci-kit related imports \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_finder(predictions , labels):\n",
    "    values, max_indices = torch.max(predictions, dim=1)\n",
    "    accuracy = ( max_indices == labels ).sum()\n",
    "    return accuracy/max_indices.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_preprocessor(base_dir:str, directory:str):\n",
    "    return os.path.join(base_dir,directory).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_image_list_from_processed_csv(csv_file):\n",
    "    ### This returns the entire list full of images to be loaded into cpu\n",
    "    ###\n",
    "    ###\n",
    "    ALL_IMAGES = []\n",
    "    start = time.time()\n",
    "    for i, items in tq(enumerate(csv_file.iloc[:,1])):\n",
    "        image = cv2.imread(items, cv2.COLOR_BGR2RGB)\n",
    "        resized = cv2.resize(image,(IMAGE_DIMS,IMAGE_DIMS))\n",
    "        ALL_IMAGES.append(resized)\n",
    "    \n",
    "    print(\"Tt took us approximately {} seconds\".format(time.time()-start))  \n",
    "    return ALL_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_encoded_labels(input_data_frame):\n",
    "    input_data_frame.labels = input_data_frame.labels.map(lambda x: x-1)\n",
    "    # return pd.get_dummies(input_data_frame.labels, prefix='labels').to_numpy()\n",
    "    return input_data_frame.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch device configurations \n",
    "BATCH_SIZE = 512\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_directory = os.path.join(os.getcwd(),'guides\\\\isolated-dataset-csv\\\\IsolatedTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\IsolatedTrain\\1\\bcc000000.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\IsolatedTrain\\1\\bcc000133.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\IsolatedTrain\\1\\bcc000134.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\IsolatedTrain\\1\\bcc000135.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\IsolatedTrain\\1\\bcc000136.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34434</th>\n",
       "      <td>171</td>\n",
       "      <td>dataset\\IsolatedTrain\\171\\bcc000067.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34435</th>\n",
       "      <td>171</td>\n",
       "      <td>dataset\\IsolatedTrain\\171\\bcc000068.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34436</th>\n",
       "      <td>171</td>\n",
       "      <td>dataset\\IsolatedTrain\\171\\bcc000069.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34437</th>\n",
       "      <td>171</td>\n",
       "      <td>dataset\\IsolatedTrain\\171\\bcc000071.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34438</th>\n",
       "      <td>171</td>\n",
       "      <td>dataset\\IsolatedTrain\\171\\bcc000111.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34439 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                directory\n",
       "0           1    dataset\\IsolatedTrain\\1\\bcc000000.bmp\n",
       "1           1    dataset\\IsolatedTrain\\1\\bcc000133.bmp\n",
       "2           1    dataset\\IsolatedTrain\\1\\bcc000134.bmp\n",
       "3           1    dataset\\IsolatedTrain\\1\\bcc000135.bmp\n",
       "4           1    dataset\\IsolatedTrain\\1\\bcc000136.bmp\n",
       "...       ...                                      ...\n",
       "34434     171  dataset\\IsolatedTrain\\171\\bcc000067.bmp\n",
       "34435     171  dataset\\IsolatedTrain\\171\\bcc000068.bmp\n",
       "34436     171  dataset\\IsolatedTrain\\171\\bcc000069.bmp\n",
       "34437     171  dataset\\IsolatedTrain\\171\\bcc000071.bmp\n",
       "34438     171  dataset\\IsolatedTrain\\171\\bcc000111.bmp\n",
       "\n",
       "[34439 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = pd.read_csv(train_csv_directory, usecols=[\"labels\",\"directory\"])\n",
    "TRAIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 170, 170, 170], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([10, 11,  9, 10, 10, 10, 10, 11,  9, 10], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN_CSV, X_VAL_CSV,Y_TRAIN, Y_VAL = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeanIsolatedCharacterDataset(Dataset):\n",
    "    def __init__(self, csv_dir_path,  transforms=None, custom_transform=None ):\n",
    "        ### complete dataset path\n",
    "        self.dataset_csv = pd.read_csv(csv_dir_path, usecols=[\"labels\",\"directory\"])  \n",
    "        \n",
    "        ### labels\n",
    "        self.labels = get_one_hot_encoded_labels(self.dataset_csv)\n",
    "        ### @previously -> self.labels = self.dataset_csv_numpy[:,0]\n",
    "        \n",
    "        ### loading dataset into memory\n",
    "        self.dataset_csv[\"directory\"] = self.dataset_csv[\"directory\"].map(lambda x: csv_preprocessor(base_dir=str(os.getcwd()), directory=str(x)))\n",
    "        self.dataset_csv_numpy = self.dataset_csv.to_numpy()\n",
    "        self.ALL_IMAGES = return_all_image_list_from_processed_csv(csv_file=self.dataset_csv)\n",
    "        \n",
    "        ### transformations to apply on images\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # convert labels to tensor \n",
    "        label = torch.tensor(self.labels[index])\n",
    "        # load single image from list of all preloaded images\n",
    "        image = self.ALL_IMAGES[index]\n",
    "        if self.transforms:\n",
    "            ## apply transforms \n",
    "            image = self.transforms(image)    \n",
    "            image = image.float()\n",
    "        label = label.long()\n",
    "        return image, label \n",
    "    \n",
    "    def __len__(self):\n",
    "        rows , _ = self.dataset_csv_numpy.shape\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolatedCharacterDataset(Dataset):\n",
    "    def __init__(self, csv_dir_path,  transforms=None, custom_transform=None ):\n",
    "        ### complete dataset path\n",
    "        self.dataset_csv = pd.read_csv(csv_dir_path, usecols=[\"labels\",\"directory\"])  \n",
    "        \n",
    "        ### labels\n",
    "        self.labels = get_one_hot_encoded_labels(self.dataset_csv)\n",
    "        ### @previously -> self.labels = self.dataset_csv_numpy[:,0]\n",
    "        \n",
    "        ### loading dataset into memory\n",
    "        self.dataset_csv[\"directory\"] = self.dataset_csv[\"directory\"].map(lambda x: csv_preprocessor(base_dir=str(os.getcwd()), directory=str(x)))\n",
    "        self.dataset_csv_numpy = self.dataset_csv.to_numpy()\n",
    "        self.ALL_IMAGES = return_all_image_list_from_processed_csv(csv_file=self.dataset_csv)\n",
    "        \n",
    "        ### transformations to apply on images\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # convert labels to tensor \n",
    "        label = torch.tensor(self.labels[index])\n",
    "        # load single image from list of all preloaded images\n",
    "        image = self.ALL_IMAGES[index]\n",
    "        if self.transforms:\n",
    "            ## apply transforms \n",
    "            image = self.transforms(image)    \n",
    "            image = image.float()\n",
    "        label = label.long()\n",
    "        return image, label \n",
    "    \n",
    "    def __len__(self):\n",
    "        rows , _ = self.dataset_csv_numpy.shape\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NORMALIZER = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),transforms.Resize((IMAGE_DIMS,IMAGE_DIMS))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676509be4cf845aba1aa214a93602cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tt took us approximately 375.04032850265503 seconds\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET = IsolatedCharacterDataset(csv_dir_path=train_csv_directory,transforms=DATA_NORMALIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(trainset, [50000, 10000])\n",
    "print(' Number of final training data ', len(train_set))\n",
    "print(' Number of validation data ', len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LOADER = DataLoader(dataset=TRAIN_DATASET,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels, kernel_size=3, stride=stride, padding=1,)\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(intermediate_channels, intermediate_channels * self.expansion, kernel_size=1, stride=1, padding=0,)\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "    \n",
    "    #Identity block\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        #x = self.relu(x) #custom \n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels change\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, intermediate_channels * 4, kernel_size=1, stride=stride,),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(img_channel=3, num_classes=171):\n",
    "    return ResNet(block, [2, 3, 5, 2], img_channel, num_classes)\n",
    "net = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  optim.Adam(net.parameters(), lr=0.07) # learning rate \n",
    "# defining the loss function\n",
    "criterion =  nn.CrossEntropyLoss() # reduction='none'\n",
    "net = net.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(ValidationLoader):\n",
    "    total_val_accuracy = 0\n",
    "    total_val_loss = 0 \n",
    "    with torch.no_grad():\n",
    "    for i, data in enumerate(ValidationLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_val_loss += loss\n",
    "        val_accuracy = accuracy_finder(predictions=outputs, labels=labels)\n",
    "        total_val_accuracy = total_val_accuracy + val_accuracy\n",
    "            \n",
    "    return (total_val_loss/len(ValidationLoader), total_val_accuracy/len(ValidationLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs:int):\n",
    "    all_training_losses = []\n",
    "    all_training_accuracy = []\n",
    "    for epoch in tq(range(epochs)):\n",
    "        total_epoch_loss = 0\n",
    "        total_accuracy_epoch = 0\n",
    "        for i, data in tqdm(enumerate(TRAIN_LOADER, 0)): \n",
    "            image,label = data\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            label = label.to(DEVICE)\n",
    "            image = image.to(DEVICE)\n",
    "            output = net(image)\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                total_epoch_loss += loss\n",
    "                batches_training_accuracy = accuracy_finder(predictions=output, labels=label)\n",
    "                total_accuracy_epoch = total_accuracy_epoch  + batches_training_accuracy   \n",
    "            \n",
    "            if i % 100 == 0 and i != 0: \n",
    "                print(\"Batch : {}/{}\".format(i, len(TRAIN_LOADER)))\n",
    "   \n",
    "        # total epoch loss \n",
    "        total_epoch_loss = total_epoch_loss / len(TRAIN_LOADER)\n",
    "        # total epoch accuracy \n",
    "        total_accuracy_epoch = total_accuracy_epoch /len(TRAIN_LOADER)\n",
    "        \n",
    "        # display the epoch training loss\n",
    "        print(\"epoch : {}/{}, loss = {:.8f}, acc = {:.8f}\".format(epoch + 1, epochs, total_epoch_loss, total_accuracy_epoch ))\n",
    "        all_training_losses.append(total_epoch_loss)\n",
    "        all_training_accuracy.append(total_accuracy_epoch)\n",
    "        \n",
    "    print(\"Training completed\")\n",
    "    return all_training_accuracy, all_training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e569d432a34c4925a73d0a310dc1e541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/50, loss = 10.27452946, acc = 0.01062730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:29,  1.32s/it]\n",
      "1it [00:00,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2/50, loss = 5.03641558, acc = 0.01579627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3/50, loss = 4.85809326, acc = 0.02364941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.31s/it]\n",
      "1it [00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4/50, loss = 4.64807129, acc = 0.03139851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:29,  1.32s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5/50, loss = 4.41309214, acc = 0.04788411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.31s/it]\n",
      "1it [00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6/50, loss = 4.13977575, acc = 0.07059653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:29,  1.31s/it]\n",
      "1it [00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7/50, loss = 3.80857754, acc = 0.10961733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8/50, loss = 3.41477132, acc = 0.16216746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9/50, loss = 3.00114059, acc = 0.22526148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10/50, loss = 2.60050344, acc = 0.30592108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 11/50, loss = 2.28198457, acc = 0.37202391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 12/50, loss = 2.01319575, acc = 0.43973845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 13/50, loss = 1.79515803, acc = 0.49033439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 14/50, loss = 1.63373280, acc = 0.53030407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 15/50, loss = 1.45948875, acc = 0.57183564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 16/50, loss = 1.34832501, acc = 0.60409582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 17/50, loss = 1.25242603, acc = 0.63272995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 18/50, loss = 1.14550567, acc = 0.65939033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 19/50, loss = 1.07238460, acc = 0.68074894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 20/50, loss = 0.98998857, acc = 0.70250273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 21/50, loss = 0.93597484, acc = 0.71683520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 22/50, loss = 0.85210884, acc = 0.73988628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 23/50, loss = 0.80945355, acc = 0.75233293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 24/50, loss = 0.74895918, acc = 0.76860869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 25/50, loss = 0.72701120, acc = 0.77455920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 26/50, loss = 0.68084651, acc = 0.78822505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 27/50, loss = 0.61737287, acc = 0.80507427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 28/50, loss = 0.58415645, acc = 0.81173092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.31s/it]\n",
      "1it [00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 29/50, loss = 0.56659329, acc = 0.82001972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 30/50, loss = 0.55412644, acc = 0.82357538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 31/50, loss = 0.52726358, acc = 0.83242083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 32/50, loss = 0.50255293, acc = 0.84041864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 33/50, loss = 0.47428894, acc = 0.84597671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 34/50, loss = 0.43029836, acc = 0.86259723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 35/50, loss = 0.43292135, acc = 0.85879886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 36/50, loss = 0.40185431, acc = 0.86814451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 37/50, loss = 0.37287903, acc = 0.87668693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.31s/it]\n",
      "1it [00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 38/50, loss = 0.38708389, acc = 0.87477934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.31s/it]\n",
      "1it [00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 39/50, loss = 0.35616073, acc = 0.88356358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40/50, loss = 0.36052784, acc = 0.88328606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 41/50, loss = 0.32816517, acc = 0.89157224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:29,  1.31s/it]\n",
      "1it [00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 42/50, loss = 0.31889075, acc = 0.89520699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 43/50, loss = 0.29852358, acc = 0.90265697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 44/50, loss = 0.27523541, acc = 0.90960670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.30s/it]\n",
      "1it [00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 45/50, loss = 0.27838078, acc = 0.90778035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:28,  1.31s/it]\n",
      "1it [00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 46/50, loss = 0.30414471, acc = 0.89943510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:32,  1.36s/it]\n",
      "1it [00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 47/50, loss = 0.29702014, acc = 0.90320265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:32,  1.35s/it]\n",
      "1it [00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 48/50, loss = 0.26100525, acc = 0.91351616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:33,  1.38s/it]\n",
      "1it [00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 49/50, loss = 0.27678183, acc = 0.90801609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [01:29,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 50/50, loss = 0.22711028, acc = 0.92660546\n",
      "\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "t_acc, t_loss = training(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model was successfully saved\n"
     ]
    }
   ],
   "source": [
    "PATH = './models/resnet_50_model_1.pth'\n",
    "# saving model\n",
    "torch.save(net.state_dict(), PATH)\n",
    "print(\"model was successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plot(t_value,title,ylabel):\n",
    "    result = []\n",
    "    for item in t_value:\n",
    "        result.append(item.cpu())\n",
    "    plt.plot(result,'b')\n",
    "    plt.title(title)\n",
    "    plt.legend(\"training\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkQUlEQVR4nO3debxW8/r/8ddVGqiURho00Nd4ErZZjinKFH4oM8d4hAzHVxzHcHwdneNriCK+kaEIJxLScFJmTruEJFQqm6Ky06za+/r98Vlbd/vs6lZ77XUP7+fjsR77vtda+76vFXtda30+n3V9zN0REZH8VS3pAEREJFlKBCIieU6JQEQkzykRiIjkOSUCEZE8p0QgIpLnlAhERPKcEoHkDTObYGbFZlYr6VhEMokSgeQFM2sDdAIcOKkKv3erqvoukc2lRCD54jzgQ+BJ4PyylWbWysxeMrMFZrbIzPqlbLvEzL4ws6VmNs3M9onWu5ntnLLfk2b2P9Hrw82syMxuNLP5wCAz287MXou+ozh63TLl9xua2SAz+z7aPjxaP9XMTkzZr4aZLTSzjjH9G0meUiKQfHEeMCRajjWzZmZWHXgNmAO0AVoAQwHM7HTg9uj3tiXcRSxK87u2BxoCrYFLCX9ng6L3OwIrgX4p+z8DbAPsATQF7o/WPw2ck7LfccA8d5+SZhwiaTHVGpJcZ2aHAuOBHdx9oZlNBx4l3CGMiNavLfc7o4GR7t63gs9zoL27z4jePwkUufstZnY4MAbY1t1XbSCejsB4d9/OzHYAvgMauXtxuf2aA18CLdx9iZn9E/i3u/9jM/8pRCqkOwLJB+cDY9x9YfT+2WhdK2BO+SQQaQXM3MzvW5CaBMxsGzN71MzmmNkS4G2gQXRH0gr4qXwSAHD374H3gP9nZg2AroQ7GpFKpY4syWlmtjVwBlA9arMHqAU0AH4AdjSzrSpIBt8CO23gY1cQmnLKbA8Upbwvf5t9PbALcIC7z4/uCD4GLPqehmbWwN0XV/BdTwEXE/5WP3D37zYQk8hm0x2B5LqTgRJgd6BjtOwGvBNtmwf0MbM6ZlbbzA6Jfm8g8Ccz29eCnc2sdbRtCnCWmVU3sy7A7zcRQz1Cv8BiM2sI3Fa2wd3nAW8AD0edyjXM7LCU3x0O7AP0IvQZiFQ6JQLJdecDg9x9rrvPL1sInbVnAicCOwNzCVf13QHc/UXgLkIz0lLCCblh9Jm9ot9bDJwdbduYB4CtgYWEfolR5bafC6wBpgM/AteUbXD3lcAwoC3wUvqHLZI+dRaLZDgzuxX4L3c/Z5M7i2wG9RGIZLCoKekiwl2DSCzUNCSSoczsEkJn8hvu/nbS8UjuUtOQiEie0x2BiEiey7o+gsaNG3ubNm2SDkNEJKtMmjRpobs3qWhb1iWCNm3aUFhYmHQYIiJZxczmbGibmoZERPKcEoGISJ5TIhARyXNZ10dQkTVr1lBUVMSqVRVW/U1U7dq1admyJTVq1Eg6FBGRCuVEIigqKqJevXq0adMGM0s6nF+5O4sWLaKoqIi2bdsmHY6ISIVyomlo1apVNGrUKKOSAICZ0ahRo4y8UxERKZMTiQDIuCRQJlPjEhEpkzOJQEQkV61ZA3ffDRMnxvP5SgSVYPHixTz88MNJhyEiOWjSJNh/f7j5ZngpphkplAgqgRKBiFS2lSvhxhvhgANg/vyQBO6+O57vyolRQ0nr3bs3M2fOpGPHjnTu3Jl77rkn6ZBEJEMtWADPPw8ffQS77gp77x2WHXZYt8+ECXDJJTBjBlx0EdxzD2y3XXwx5VwiuOYamDKlcj+zY0d44IENb+/Tpw9Tp05lSmV/sYhUCXf45ht4++2wfPwx1K4NDRqsW7bbLiwFBXDoofBbHg1asQJeeQUGD4bRo6GkBJo2De/LNGsWzjV168KwYdCuHfzrX3DUUZV7rBXJuUQgIrIp7vDllzB+/LqT//ffh20NG4Y2+ZISWLQIZs6E4mJYvBjWrg37bLstdO4Mxx0HXbuufzVfUgLffQezZoXkMmFCaNZZtgxatYIbboCzz4Y994Sff4ZPPgmJ5+OPw0XsrFlw/fXw17/CNttUzb9HziWCjV25i0j+mjMHxo2DN98My7x5YX3z5nDYYeuW3XaDahX0nrqHZPDWWzByZFiGDQvb9tkHGjUKJ/45c8IonzL168OZZ4aTf6dO6392/frrvjdJOZcIklCvXj2WLl2adBgieW/FinAinj07nJRnzw7LpEnhShtCk8yRR4bliCNgp50gncd9zELT0Mknh8UdPvsMXn8d3ngjJIl99oHTToO2bUPTTtu2sOOOv60ZKQlKBJWgUaNGHHLIIey555507dpVncUiVWT58tC888YbMGrUupN9mZo1oXVr+N3voFev0N6+++7pnfg3xQw6dAjLTTdt+eclSYmgkjz77LNJhyCSM1avDlfbJSWhKaV69XU/16yBd94JTTMTJsAvv0CdOuEk/4c/hKvwNm3Csv32FTfzyPqUCEQkIxQXhyv7ESPCzyVLNr7/LrvAFVeEDttOnaBWraqJMxcpEYhIbJYtC0MgX3stdM6WDcFMXYqL4dVXw8idkpIwjPKMM8KonDp1oLQ0rC/7CbDvvqENXipHziQCd8/IAm/unnQIIlXqm29CB+prr4X2+9Wrw+iYnXaC6dPXDcVM/dPYc8/wFO1JJ8F++6k5p6rlRCKoXbs2ixYtyrhS1GXzEdSuXTvpUERiUzZ6ZtiwMF5+6tSwfpdd4Kqr4IQT4JBD1h85U1oamn6Ki2GrrcL4eklOTiSCli1bUlRUxIIFC5IO5T+UzVAmkk3cw1X9s8+Gppp27dYtbdqEp24LC8PJf9iwUAqhWrXQVn/ffeHk3779hj+/WrV1T+xK8nIiEdSoUUMzgIlUki++gGuvDaUQmjQJQzRXrFh/n3r1YOnScDV/5JHhadmTTw5j9CX75EQiEJEtV1wMd9wB/fqFejf33w89e4aT/Y8/riuZMGtWKKFwwAGhTb9hw6Qjly2lRCCS51avhieegFtuCcngkkvgzjvD3UCZZs3CctBBycUp8VEiEMkjK1bAp5+GAmeTJ4efn30WksHvfw99+8JeeyUdpVQ1JQKRHLZ6Nbz/fmjvHz06VLosLQ3bGjYMtXF69Qo1d7p0qZzSC5J9lAhEcszMmaHuzujRYRz/smWhnf/gg+HPfw4n/332CUM2deIXUCIQyXqlpfDvf4fSDK+8AtOmhfXt2sG558Kxx4Yr/m23TTZOyVxKBCJZZuVKmDs3PKX7+uuhPMP8+aEg22GHwaWXwvHHw847Jx2pZAslApEMVVZi+d1319XVnzMnnPTL1K0bZsjq1i0UX4tzXlvJXUoEIhnk66/XzX711luhxHKNGmFykzZtwpV+69bhddu2oS6Pqm7Kloo1EZhZF6AvUB0Y6O59ym2vDwwGdoxi+V93HxRnTCKZomzC9PfeC8u4caFUA6wrsdy1a2ju0cle4hRbIjCz6kB/oDNQBEw0sxHuPi1lt57ANHc/0cyaAF+a2RB3Xx1XXCJJ+uqrcLX/3nuhyaesmWfbbeHQQ+Gaa8LJXyWWpSrFeUewPzDD3WcBmNlQoBuQmggcqGehZGhd4CdgbYwxiSSiuBhuuw0efjjU1G/dOtToOeSQkAD22CN09ookIc5E0AL4NuV9EXBAuX36ASOA74F6QHd3L40xJpEqVVICAweG8fvFxXD55dC7t8ouS2aJc/qHih5VKT9Ly7HAFKA50BHoZ2b/MdrZzC41s0IzK8zEUtMiFXn3XSgoCCf/PfYIJR3691cSkMwTZyIoAlL/l29JuPJPdSHwkgczgG+AXct/kLs/5u4F7l7QJLUSlkgGmjYNzjwz1OZfuBCGDg2TrKuGj2SqOBPBRKC9mbU1s5pAD0IzUKq5wFEAZtYM2AWYFWNMIrGZOBFOPTVc/Y8YEap5Tp8O3burlINkttj6CNx9rZldCYwmDB99wt0/N7PLo+0DgDuBJ83sM0JT0o3uvjCumEQqm3u42v/b38Ik7Q0awF/+AldfDY0bJx2dSHpifY7A3UcCI8utG5Dy+nvgmDhjEKls8+eHq/+JE0Nxt4kTQ63+f/wDLrtMNX0k++jJYpFNmDsXhgxZd/IvKgrrq1WD3/0OHnkELrggzOMrko2UCEQ2YOlS6NMnTMa+alUo4tapUyjrsN9+sPfeUKdO0lGKbDklApFySkrgySdDZ+/8+XDWWaEPoHXrpCMTiYcSgUiK8ePhuutgypQwP+/w4WGSdpFcFufwUZGsUFoa6v8cc0wo+1BcHMb+v/eekoDkB90RSN5aujQ0AT30UCj/3Lw5/P3vYeinOn4lnygRSN6ZPRv69oUnnoAlS8JV/7PPwmmnhdr/IvlGiUDyyvPPwx/+AKtXwxlnhKt/Nf9IvlMikLxQUgI33QT33BNKPz/3nIq/iZRRIpCc99NP0KMHjB0Lf/wjPPAA1KyZdFQimUOJQHLap5/CKaeEp4EHDoSLLko6IpHMo+GjkpPcQ3/AQQeFp4LfektJQGRDlAgkp7jDm2/C4YeH5qCOHWHSJDjwwKQjE8lcSgSSE9xh3Dg47DA46iiYMQMefDA8Kbz99klHJ5LZlAgkq7mHeQA6dYKjj4ZvvoF+/WDmTLjqKnUKi6RDncWStZYvhyuugKefhpYtw3zAF10EtWolHZlIdlEikKw0bRqcfjp88QXcdlt4RkAJQGTzKBFI1nnmGbj8cqhbNzwbcNRRSUckkt3URyBZY+VKuPhiOO+8MDHMxx8rCYhUBiUCyQpffRWGgD7+ONx8c+ggbt486ahEcoOahiTjDRkSJoWvVSvMG9C1a9IRieQW3RFIxlq+PIwCOuecMD/wJ58oCYjEQYlAMtLnn8P++8OgQWHu4PHjwxBREal8ahqSjOIeJoy56irYdlsYMyY8KCYi8dEdgWSMNWvCpDEXXwwHHxwmkFcSEImfEoFkhJUr4dRTwxzCt94Ko0erRpBIVVHTkCTu55/hxBPh3Xfh4YfD5DEiUnWUCCRRP/wAXbrA1KlhAvkePZKOSCT/KBFIYmbPhmOOCbOHvfpqSAgiUvWUCCQR06aFJLB8eXhK+OCDk45IJH8pEUiV++STUCOoRo0whWSHDklHJJLflAikSpUNCd166/CQ2M47Jx2RiGj4qFSZsmqh22wDEyYoCYhkCiUCqRJlSaBu3ZAEdtop6YhEpIwSgcRu8uSQBOrVC0mgXbukIxKRVLEmAjPrYmZfmtkMM+u9gX0ON7MpZva5mb0VZzxS9SZPDn0C224bkkDbtklHJCLlxdZZbGbVgf5AZ6AImGhmI9x9Wso+DYCHgS7uPtfMmsYVj1S9zz5bPwm0aZN0RCJSkTjvCPYHZrj7LHdfDQwFupXb5yzgJXefC+DuP8YYj1Shb78NcwdsvbWSgEimizMRtAC+TXlfFK1L9V/AdmY2wcwmmdl5FX2QmV1qZoVmVrhgwYKYwpXKUlwcnhJeuhTeeENJQCTTxfkcgVWwziv4/n2Bo4CtgQ/M7EN3/2q9X3J/DHgMoKCgoPxnSAZZtQq6dYMZM2DUKD0sJpIN4kwERUCrlPctge8r2Gehuy8HlpvZ28BewFdI1ikpCdNKvvMODB0KRxyRdEQiko44m4YmAu3NrK2Z1QR6ACPK7fMK0MnMtjKzbYADgC9ijEli4g7XXAPDhsF990H37klHJCLpiu2OwN3XmtmVwGigOvCEu39uZpdH2we4+xdmNgr4FCgFBrr71Lhikvj84x/Qrx9cfz1ce23S0YjIb2Hu2dXkXlBQ4IWFhUmHISlefjnMLnbmmTB4MFTTY4oiGcfMJrl7QUXb9CcrW2TevDDHcEEBDBqkJCCSjfRnK5vNHS66CFasgGeegVq1ko5IRDZHWonAzIaZ2fFmpsQhv3rssfCcwD33wK67Jh2NiGyudE/sjxCeAv7azPqYmf7s89zXX8N110HnznDFFUlHIyJbIq1E4O7/cvezgX2A2cBYM3vfzC40sxpxBiiZZ+1aOO+80BSkfgGR7Jf2n7CZNQIuAC4GPgb6EhLD2Fgik4zVpw98+CE8/DC0KF80RESyTlrPEZjZS8CuwDPAie4+L9r0vJlpLGcemTQJ7rgDevQIi4hkv3QfKOvn7m9WtGFD41Il96xcGUpINGsG/fsnHY2IVJZ0m4Z2i+YOAMDMtjMzdRHmmd69Yfr00C/QsGHS0YhIZUk3EVzi7ovL3rh7MXBJLBFJRnr9dXjwQbj66jBSSERyR7qJoJqZ/VpWOpp9rGY8IUmmmTcPLrwwlJT++9+TjkZEKlu6fQSjgRfMbABhToHLgVGxRSUZo7QULrgAli2D556D2rWTjkhEKlu6ieBG4DLgj4QJZ8YAA+MKSjLH/ffDmDEwYADsvnvS0YhIHNJKBO5eSni6+JF4w5FMMnky3HQTnHwyXHpp0tGISFzSfY6gPXA3sDvwa+OAu7eLKS5J2PLloax0kyYwcCBYRROPikhOSLdpaBBwG3A/cARwIRXPSSw5olevUE9o3Dho1CjpaEQkTumOGtra3ccRJrKZ4+63A0fGF5Yk6cUX4fHHw3MDmndYJPele0ewKipB/XU0/eR3QNP4wpKk/Pwz9OwJ++0XSkmISO5LNxFcA2wDXA3cSWgeOj+mmCRBd90FCxeGeQZqqK6sSF7YZCKIHh47w91vAJYR+gckB82cCX37wvnnw777Jh2NiFSVTfYRuHsJsG/qk8WSm/77v8NdwF13JR2JiFSldJuGPgZeMbMXgeVlK939pViikio3YQK89BLceSc0b550NCJSldJNBA2BRaw/UsgBJYIcUFISpp1s1Qquvz7paESkqqX7ZLH6BXLYU0/Bxx+HWkJbb510NCJS1dJ9sngQ4Q5gPe7+h0qPSKrU0qVw881w0EHQvXvS0YhIEtJtGnot5XVt4BTg+8oPR6panz7www/wyisqIyGSr9JtGhqW+t7MngP+FUtEUmVmz4Z77w3TTx5wQNLRiEhS0i0xUV57YMfKDESqXu/eUK0a3H130pGISJLS7SNYyvp9BPMJcxRIlpo+HZ5/Hm65BVq2TDoaEUlSuk1D9eIORKpWv35QsyZcdVXSkYhI0tJqGjKzU8ysfsr7BmZ2cmxRSayWLAlDRnv0gKYqHSiS99LtI7jN3X8ue+PuiwnzE0gWevLJMAex7gZEBNJPBBXtl+7QU8kgpaWhWejAA6GgIOloRCQTpJsICs3sPjPbyczamdn9wKQ4A5N4jB0bZh678sqkIxGRTJFuIrgKWA08D7wArAR6buqXzKyLmX1pZjPMrPdG9tvPzErM7LQ045HN9NBD0KwZnH560pGISKZId9TQcmCDJ/KKRPMY9Ac6A0XARDMb4e7TKtjv78Do3/L58tvNnAkjR8Jf/hJGDImIQPqjhsaaWYOU99uZ2aZO3PsDM9x9lruvBoYC3SrY7ypgGPBjeiHL5urfH6pXh8suSzoSEckk6TYNNY5GCgHg7sVses7iFsC3Ke+LonW/MrMWhLpFAzb2QWZ2qZkVmlnhggUL0gxZUi1bBk88AaedpvkGRGR96SaCUjP7taSEmbWhgmqk5VRUwqz87zwA3BjNgrZB7v6Yuxe4e0GTJk3SCFfKGzw4TEyvTmIRKS/dIaB/Bt41s7ei94cBl27id4qAVinvW/KfFUsLgKHRLJiNgePMbK27D08zLkmDexgyuvfecPDBSUcjIpkm3c7iUWZWQDj5TwFeIYwc2piJQHszawt8B/QAzir3uW3LXpvZk8BrSgKVb8IE+Pzz0DSkUtMiUl66RecuBnoRruqnAAcCH7D+1JXrcfe1ZnYlYTRQdeAJd//czC6Ptm+0X0Aqz0MPQaNGoaSEiEh56TYN9QL2Az509yPMbFfgjk39kruPBEaWW1dhAnD3C9KMRX6DOXPCpDM33KBpKEWkYul2Fq9y91UAZlbL3acDu8QXllSW/v1Dc9AVVyQdiYhkqnTvCIqi5wiGA2PNrBhNVZnxli+H//s/OPVU2FHTCInIBqTbWXxK9PJ2MxsP1AdGxRaVVIqnn4bFi6FXr6QjEZFM9psriLr7W5veS5JWWgoPPhgqjGrIqIhsjEpJ56gxY8J0lM88oyGjIrJxmzt5vWS4vn1h++3hjDOSjkREMp0SQQ6aPh1GjQojhVRlVEQ2RYkgBz34INSqpSqjIpIeJYIcU1wcJqY/6yxNTC8i6VEiyDEDB8KKFRoyKiLpUyLIIWvXhiqjhx8Oe+2VdDQiki00fDSHDB8Oc+eGPgIRkXTpjiCH9O0LbdvCCSckHYmIZBMlghwxaRK8+y5cfXWYl1hEJF1KBDni8cdDmekLL0w6EhHJNkoEOWD1anj+eTj5ZKhfP+loRCTbKBHkgNGj4aef4Oyzk45ERLKREkEOGDIEGjeGY45JOhIRyUZKBFluyZIwFWX37lCjRtLRiEg2UiLIci+/DKtWqVlIRDafEkGWGzwY2rWDAw9MOhIRyVZKBFls3jx4881wN6DJZ0RkcykRZLGhQ8OUlGoWEpEtoUSQxQYPDnMS77JL0pGISDZTIshS06fD5Mm6GxCRLadEkKWGDIFq1aBHj6QjEZFsp0SQhdxDIjj66DBBvYjIllAiyEIffADffKNmIRGpHEoEWWjIkFBp9JRTko5ERHKBEkGWWbMmVBrt1g3q1Us6GhHJBUoEWWb0aFi0SM1CIlJ5lAiyzKBB0KgRHHts0pGISK5QIsgiM2aEInOXXaZKoyJSeZQIssh994UEcOWVSUciIrkk1kRgZl3M7Eszm2FmvSvYfraZfRot75vZXnHGk80WLAjNQueeCzvskHQ0IpJLYksEZlYd6A90BXYHzjSz3cvt9g3we3fvANwJPBZXPNmuf/8w78D11ycdiYjkmjjvCPYHZrj7LHdfDQwFuqXu4O7vu3tx9PZDoGWM8WStFStCIjjxRNhtt6SjEZFcE2ciaAF8m/K+KFq3IRcBb1S0wcwuNbNCMytcsGBBJYaYHZ56ChYuhD/9KelIRCQXxZkIKpoqxSvc0ewIQiK4saLt7v6Yuxe4e0GTJk0qMcTMV1IC994L++8PnTolHY2I5KI4E0ER0CrlfUvg+/I7mVkHYCDQzd0XxRhPVho+HGbOhBtu0CxkIhKPOBPBRKC9mbU1s5pAD2BE6g5mtiPwEnCuu38VYyxZyR3uuSfMSay6QiISl63i+mB3X2tmVwKjgerAE+7+uZldHm0fANwKNAIetnC5u9bdC+KKKdu89x589BH06wfVqycdjYjkKnOvsNk+YxUUFHhhYWHSYVSJbt1CMpg7F7bZJuloRCSbmdmkDV1o68niDDV9OowYAT17KgmISLyUCDLUvfdC7dohEYiIxEmJIAPNmAFPPgkXXghNmyYdjYjkOiWCDHTzzVCrFtx6a9KRiEg+UCLIMB99BC++GJ4i1sT0IlIVlAgyiHt4cKxZMxWXE5GqE9tzBPLbvfoqvPMOPPKI5iMWkaqjO4IMsXYt3Hgj7LILXHxx0tGISD7RHUGGePzx8OzA8OGwlf6riEgV0h1BBli2DG67DQ49FE46KeloRCTf6NozA9x7L/zwQ7gbUIVREalquiNI2Pz5ocLo6afDgQcmHY2I5CMlgoTdfjv88gv87W9JRyIi+UqJIEHvvw8DB8If/wg775x0NCKSr5QIEvLTT3DmmdC6Ndx5Z9LRiEg+U2dxAtzhootg3rww30D9+klHJCL5TIkgAf37hxFC994L++2XdDQiku/UNFTFpkwJdYSOPx6uvTbpaERElAiq1LJl0L07NGkS5hvQMwMikgnUNFSFrrgiTDozfjw0bpx0NCIige4IqshTT8Ezz4RSEocdlnQ0IiLrKBFUgXffDXcDRxwBf/5z0tGIiKxPiSBG7vDQQyEBtGgBgwdD9epJRyUisj4lgpisWAHnnw9XXw3HHQcTJ0Lz5klHJSLyn5QIYjBrFhx8cLgDuPNOePllPTQmIplLo4Yq2ahRcNZZoVnotdfC3YCISCbTHUElWbwYrrsunPhbtYLCQiUBEckOSgRbaO1aGDAA2reHBx6ASy4JVUV32inpyERE0qNEsAXGjYO99w5lpPfYAyZPhkcfhTp1ko5MRCR9SgS/UWlpGAHUrRscfXQoG/HPf4anhTt2TDo6EZHfTp3FaZgzB8aODcu4cbBoEdStC3ffDddcA7VrJx2hiMjmUyKowJIl4Qp/7FgYMwa+/jqsb94cTjgBOneGY49VvSARyQ1KBEBJSRjlM2ZMWD74IKyrUwcOPxx69gwn/912U8VQEck9eZcIli2DqVPh00/XLZ98Eu4CzGDffeHGG+GYY+Cgg6BmzaQjFhGJV6yJwMy6AH2B6sBAd+9TbrtF248DVgAXuPvkOGIZOTKUe5g5c926evWgQwc4++xw5X/UUdCoURzfLiKSuWJLBGZWHegPdAaKgIlmNsLdp6Xs1hVoHy0HAI9EPytd06awzz5wwQXh5N+hQ5g4Xk09IpLv4rwj2B+Y4e6zAMxsKNANSE0E3YCn3d2BD82sgZnt4O7zKjuYggJ44YXK/lQRkewX53MELYBvU94XRet+6z6Y2aVmVmhmhQsWLKj0QEVE8lmciaCiRhffjH1w98fcvcDdC5o0aVIpwYmISBBnIigCWqW8bwl8vxn7iIhIjOJMBBOB9mbW1sxqAj2AEeX2GQGcZ8GBwM9x9A+IiMiGxdZZ7O5rzexKYDRh+OgT7v65mV0ebR8AjCQMHZ1BGD56YVzxiIhIxWJ9jsDdRxJO9qnrBqS8dqBnnDGIiMjGqfqoiEieUyIQEclzFlpnsoeZLQDmbOavNwYWVmI42SRfj13HnV903BvW2t0rHH+fdYlgS5hZobsXJB1HEvL12HXc+UXHvXnUNCQikueUCERE8ly+JYLHkg4gQfl67Dru/KLj3gx51UcgIiL/Kd/uCEREpBwlAhGRPJc3icDMupjZl2Y2w8x6Jx1PXMzsCTP70cympqxraGZjzezr6Od2ScYYBzNrZWbjzewLM/vczHpF63P62M2stpn928w+iY77jmh9Th93GTOrbmYfm9lr0fucP24zm21mn5nZFDMrjNZt0XHnRSJImTazK7A7cKaZ7Z5sVLF5EuhSbl1vYJy7twfGRe9zzVrgenffDTgQ6Bn9N871Y/8FONLd9wI6Al2iSr65ftxlegFfpLzPl+M+wt07pjw7sEXHnReJgJRpM919NVA2bWbOcfe3gZ/Kre4GPBW9fgo4uSpjqgruPs/dJ0evlxJODi3I8WP3YFn0tka0ODl+3ABm1hI4HhiYsjrnj3sDtui48yURpDUlZg5rVjbPQ/SzacLxxMrM2gB7Ax+RB8ceNY9MAX4Exrp7Xhw38ADw30Bpyrp8OG4HxpjZJDO7NFq3RccdaxnqDJLWlJiS/cysLjAMuMbdl5hV9J8+t7h7CdDRzBoAL5vZngmHFDszOwH40d0nmdnhCYdT1Q5x9+/NrCkw1symb+kH5ssdQb5PifmDme0AEP38MeF4YmFmNQhJYIi7vxStzotjB3D3xcAEQh9Rrh/3IcBJZjab0NR7pJkNJvePG3f/Pvr5I/Ayoel7i447XxJBOtNm5rIRwPnR6/OBVxKMJRYWLv0fB75w9/tSNuX0sZtZk+hOADPbGjgamE6OH7e73+TuLd29DeHv+U13P4ccP24zq2Nm9cpeA8cAU9nC486bJ4vN7DhCm2LZtJl3JRtRPMzsOeBwQlnaH4DbgOHAC8COwFzgdHcv36Gc1czsUOAd4DPWtRnfTOgnyNljN7MOhM7B6oQLuxfc/a9m1ogcPu5UUdPQn9z9hFw/bjNrR7gLgNC0/6y737Wlx503iUBERCqWL01DIiKyAUoEIiJ5TolARCTPKRGIiOQ5JQIRkTynRCASMzM7vKw6pkgmUiIQEclzSgQiETM7J6rtP8XMHo2KuS0zs3vNbLKZjTOzJtG+Hc3sQzP71MxeLqv/bmY7m9m/ovkBJpvZTtHH1zWzf5rZdDMbEj0JjZn1MbNp0ef8b0KHLnlOiUAEMLPdgO6Egl4dgRLgbKAOMNnd9wHeIjypDfA0cKO7dyA8zVy2fgjQP5of4GBgXrR+b+AawnwY7YBDzKwhcAqwR/Q5/xPnMYpsiBKBSHAUsC8wMSrpfBThhF0KPB/tMxg41MzqAw3c/a1o/VPAYVENmBbu/jKAu69y9xXRPv929yJ3LwWmAG2AJcAqYKCZnQqU7StSpZQIRAIDnopmfero7ru4++0V7Lexmiwbq3n9S8rrEmArd19LqBw5jDCRyKjfFrJI5VAiEAnGAadFNd7L5oBtTfgbOS3a5yzgXXf/GSg2s07R+nOBt9x9CVBkZidHn1HLzLbZ0BdGcyfUd/eRhGajjpV+VCJpyJeJaUQ2yt2nmdkthJmfqgFrgJ7AcmAPM5sE/EzoR4BQ6ndAdKKfBVwYrT8XeNTM/hp9xukb+dp6wCtmVptwN3FtJR+WSFpUfVRkI8xsmbvXTToOkTipaUhEJM/pjkBEJM/pjkBEJM8pEYiI5DklAhGRPKdEICKS55QIRETy3P8Hoqf1O7JFpQ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_plot(t_value=t_acc, title=\"Accuracy\", ylabel=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_plot(t_value=t_loss, title=\"Loss\", ylabel=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
