{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required python standard libraries\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All torch related imports \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cv2 to read an image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All sci-kit related imports \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = os.path.join(os.getcwd(),'guides\\\\isolated-dataset-csv\\\\IsolatedTrain.csv')\n",
    "test_directory = os.path.join(os.getcwd(),'guides\\\\isolated-dataset-csv\\\\IsolatedTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(train_directory, usecols=[\"labels\",\"directory\"])\n",
    "test_csv = pd.read_csv(test_directory, usecols=[\"labels\",\"directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_preprocessor(base_dir:str, directory:str):\n",
    "    return os.path.join(base_dir,directory).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_image_list_from_processed_csv(csv_file):\n",
    "    ### This returns the entire list full of images to be loaded into cpu\n",
    "    ###\n",
    "    ###\n",
    "    ALL_IMAGES = []\n",
    "    start = time.time()\n",
    "    for i, items in tq(enumerate(csv_file.iloc[:,1])):\n",
    "        image = cv2.imread(items, cv2.COLOR_BGR2RGB)\n",
    "        resized = cv2.resize(image,(224,224))\n",
    "        ALL_IMAGES.append(resized)\n",
    "    \n",
    "    print(\"Tt took us approximately {} seconds\".format(time.time()-start))  \n",
    "    return ALL_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolatedCharacterDataset(Dataset):\n",
    "    def __init__(self, csv_dir_path,  transforms=None, custom_transform=None ):\n",
    "        ### complete dataset path\n",
    "        self.dataset_csv = pd.read_csv(csv_dir_path, usecols=[\"labels\",\"directory\"])  \n",
    "        self.dataset_csv[\"directory\"] = self.dataset_csv[\"directory\"].map(lambda x: csv_preprocessor(base_dir=str(os.getcwd()), directory=str(x)))\n",
    "        self.dataset_csv_numpy = self.dataset_csv.to_numpy()\n",
    "        self.ALL_IMAGES = return_all_image_list_from_processed_csv(csv_file=self.dataset_csv)\n",
    "        \n",
    "        ### labels\n",
    "        self.labels = self.dataset_csv_numpy[:,0]\n",
    "        ### images directories\n",
    "        self.image_directories = self.dataset_csv_numpy[:,1]\n",
    "        ### transformations to apply on images\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # convert labels to tensor \n",
    "        label = torch.tensor(self.labels[index])\n",
    "        \n",
    "        # load single image from list of all preloaded images\n",
    "        image = self.ALL_IMAGES[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            ## apply transforms \n",
    "            image = self.transforms(image)\n",
    "            image = image.float()\n",
    "        label = label.long().subtract(1)\n",
    "        return image, label \n",
    "    \n",
    "    def __len__(self):\n",
    "        rows,_ = self.dataset_csv_numpy.shape\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NORMALIZER = transforms.Compose([transforms.ToTensor(),transforms.Resize(224),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eefe38471f34f1ca102db35b08302dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tt took us approximately 547.6679956912994 seconds\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET = IsolatedCharacterDataset(csv_dir_path= train_directory,transforms=DATA_NORMALIZER)\n",
    "TRAIN_LOADER = DataLoader(dataset=TRAIN_DATASET,batch_size=BATCH_SIZE,num_workers=0,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> batch no  0, time taken 0.0\n",
      "---> batch no  1, time taken 0.0019941329956054688\n",
      "---> batch no  2, time taken 0.0019941329956054688\n",
      "---> batch no  3, time taken 0.001994609832763672\n",
      "---> batch no  4, time taken 0.0019941329956054688\n",
      "---> batch no  5, time taken 0.0019943714141845703\n",
      "---> batch no  6, time taken 0.0029897689819335938\n",
      "---> batch no  7, time taken 0.001993894577026367\n",
      "---> batch no  8, time taken 0.001994609832763672\n",
      "---> batch no  9, time taken 0.0019943714141845703\n",
      "---> batch no  10, time taken 0.0019943714141845703\n",
      "---> batch no  11, time taken 0.0019941329956054688\n",
      "---> batch no  12, time taken 0.0019948482513427734\n",
      "---> batch no  13, time taken 0.001994609832763672\n",
      "---> batch no  14, time taken 0.001994609832763672\n",
      "---> batch no  15, time taken 0.001994609832763672\n",
      "---> batch no  16, time taken 0.0019943714141845703\n",
      "---> batch no  17, time taken 0.001993894577026367\n",
      "---> batch no  18, time taken 0.0029916763305664062\n",
      "---> batch no  19, time taken 0.0019948482513427734\n",
      "---> batch no  20, time taken 0.001993894577026367\n",
      "---> batch no  21, time taken 0.001993894577026367\n",
      "---> batch no  22, time taken 0.0019989013671875\n",
      "---> batch no  23, time taken 0.0019941329956054688\n",
      "---> batch no  24, time taken 0.0019948482513427734\n",
      "---> batch no  25, time taken 0.0029900074005126953\n",
      "---> batch no  26, time taken 0.00299072265625\n",
      "---> batch no  27, time taken 0.0019936561584472656\n",
      "---> batch no  28, time taken 0.0019943714141845703\n",
      "---> batch no  29, time taken 0.002991199493408203\n",
      "---> batch no  30, time taken 0.002991914749145508\n",
      "---> batch no  31, time taken 0.0019943714141845703\n",
      "---> batch no  32, time taken 0.0019941329956054688\n",
      "---> batch no  33, time taken 0.001994609832763672\n",
      "---> batch no  34, time taken 0.0019943714141845703\n",
      "---> batch no  35, time taken 0.0019943714141845703\n",
      "---> batch no  36, time taken 0.002990245819091797\n",
      "---> batch no  37, time taken 0.001994609832763672\n",
      "---> batch no  38, time taken 0.001993894577026367\n",
      "---> batch no  39, time taken 0.001993894577026367\n",
      "---> batch no  40, time taken 0.001995086669921875\n",
      "---> batch no  41, time taken 0.0029909610748291016\n",
      "---> batch no  42, time taken 0.001993894577026367\n",
      "---> batch no  43, time taken 0.001993417739868164\n",
      "---> batch no  44, time taken 0.0029916763305664062\n",
      "---> batch no  45, time taken 0.0019943714141845703\n",
      "---> batch no  46, time taken 0.001993894577026367\n",
      "---> batch no  47, time taken 0.001995086669921875\n",
      "---> batch no  48, time taken 0.0029909610748291016\n",
      "---> batch no  49, time taken 0.0020012855529785156\n",
      "---> batch no  50, time taken 0.001993894577026367\n",
      "---> batch no  51, time taken 0.001994609832763672\n",
      "---> batch no  52, time taken 0.0019943714141845703\n",
      "---> batch no  53, time taken 0.00299072265625\n",
      "---> batch no  54, time taken 0.0029909610748291016\n",
      "---> batch no  55, time taken 0.0029909610748291016\n",
      "---> batch no  56, time taken 0.0029878616333007812\n",
      "---> batch no  57, time taken 0.0025076866149902344\n",
      "---> batch no  58, time taken 0.0019931793212890625\n",
      "---> batch no  59, time taken 0.00299072265625\n",
      "---> batch no  60, time taken 0.0029942989349365234\n",
      "---> batch no  61, time taken 0.002991914749145508\n",
      "---> batch no  62, time taken 0.0029909610748291016\n",
      "---> batch no  63, time taken 0.0019948482513427734\n",
      "---> batch no  64, time taken 0.0019941329956054688\n",
      "---> batch no  65, time taken 0.00299072265625\n",
      "---> batch no  66, time taken 0.001993894577026367\n",
      "---> batch no  67, time taken 0.002991914749145508\n",
      "---> batch no  68, time taken 0.001994609832763672\n",
      "---> batch no  69, time taken 0.0029897689819335938\n",
      "---> batch no  70, time taken 0.0029904842376708984\n",
      "---> batch no  71, time taken 0.001994609832763672\n",
      "---> batch no  72, time taken 0.0019943714141845703\n",
      "---> batch no  73, time taken 0.001994609832763672\n",
      "---> batch no  74, time taken 0.001994609832763672\n",
      "---> batch no  75, time taken 0.0019943714141845703\n",
      "---> batch no  76, time taken 0.0019941329956054688\n",
      "---> batch no  77, time taken 0.0029914379119873047\n",
      "---> batch no  78, time taken 0.002991914749145508\n",
      "---> batch no  79, time taken 0.001994609832763672\n",
      "---> batch no  80, time taken 0.0020003318786621094\n",
      "---> batch no  81, time taken 0.0019941329956054688\n",
      "---> batch no  82, time taken 0.0019948482513427734\n",
      "---> batch no  83, time taken 0.0019941329956054688\n",
      "---> batch no  84, time taken 0.0029904842376708984\n",
      "---> batch no  85, time taken 0.0019943714141845703\n",
      "---> batch no  86, time taken 0.001993894577026367\n",
      "---> batch no  87, time taken 0.0019943714141845703\n",
      "---> batch no  88, time taken 0.0029904842376708984\n",
      "---> batch no  89, time taken 0.0019943714141845703\n",
      "---> batch no  90, time taken 0.0015065670013427734\n",
      "---> batch no  91, time taken 0.0019936561584472656\n",
      "---> batch no  92, time taken 0.0020084381103515625\n",
      "---> batch no  93, time taken 0.0019941329956054688\n",
      "---> batch no  94, time taken 0.001973390579223633\n",
      "---> batch no  95, time taken 0.0019943714141845703\n",
      "---> batch no  96, time taken 0.002991199493408203\n",
      "---> batch no  97, time taken 0.00299072265625\n",
      "---> batch no  98, time taken 0.0019941329956054688\n",
      "---> batch no  99, time taken 0.0024995803833007812\n",
      "---> batch no  100, time taken 0.0029916763305664062\n",
      "---> batch no  101, time taken 0.001995563507080078\n",
      "---> batch no  102, time taken 0.002991914749145508\n",
      "---> batch no  103, time taken 0.001994609832763672\n",
      "---> batch no  104, time taken 0.001994609832763672\n",
      "---> batch no  105, time taken 0.0019941329956054688\n",
      "---> batch no  106, time taken 0.001994609832763672\n",
      "---> batch no  107, time taken 0.001994609832763672\n",
      "---> batch no  108, time taken 0.0019981861114501953\n",
      "---> batch no  109, time taken 0.0019948482513427734\n",
      "---> batch no  110, time taken 0.002992391586303711\n",
      "---> batch no  111, time taken 0.003996610641479492\n",
      "---> batch no  112, time taken 0.0029916763305664062\n",
      "---> batch no  113, time taken 0.002992868423461914\n",
      "---> batch no  114, time taken 0.002000093460083008\n",
      "---> batch no  115, time taken 0.001994609832763672\n",
      "---> batch no  116, time taken 0.004987239837646484\n",
      "---> batch no  117, time taken 0.001995086669921875\n",
      "---> batch no  118, time taken 0.0029909610748291016\n",
      "---> batch no  119, time taken 0.002991199493408203\n",
      "---> batch no  120, time taken 0.001993894577026367\n",
      "---> batch no  121, time taken 0.001995086669921875\n",
      "---> batch no  122, time taken 0.0029926300048828125\n",
      "---> batch no  123, time taken 0.0029916763305664062\n",
      "---> batch no  124, time taken 0.0019931793212890625\n",
      "---> batch no  125, time taken 0.0029914379119873047\n",
      "---> batch no  126, time taken 0.0019936561584472656\n",
      "---> batch no  127, time taken 0.0020029544830322266\n",
      "---> batch no  128, time taken 0.001994609832763672\n",
      "---> batch no  129, time taken 0.0029904842376708984\n",
      "---> batch no  130, time taken 0.0019941329956054688\n",
      "---> batch no  131, time taken 0.0019943714141845703\n",
      "---> batch no  132, time taken 0.001993894577026367\n",
      "---> batch no  133, time taken 0.0029904842376708984\n",
      "---> batch no  134, time taken 0.0029926300048828125\n",
      "---> batch no  135, time taken 0.0029904842376708984\n",
      "---> batch no  136, time taken 0.00299072265625\n",
      "---> batch no  137, time taken 0.0019941329956054688\n",
      "---> batch no  138, time taken 0.0029878616333007812\n",
      "---> batch no  139, time taken 0.0019948482513427734\n",
      "---> batch no  140, time taken 0.001995086669921875\n",
      "---> batch no  141, time taken 0.0019953250885009766\n",
      "---> batch no  142, time taken 0.0019943714141845703\n",
      "---> batch no  143, time taken 0.002991914749145508\n",
      "---> batch no  144, time taken 0.0019941329956054688\n",
      "---> batch no  145, time taken 0.001993894577026367\n",
      "---> batch no  146, time taken 0.001993894577026367\n",
      "---> batch no  147, time taken 0.0019969940185546875\n",
      "---> batch no  148, time taken 0.002993345260620117\n",
      "---> batch no  149, time taken 0.0029914379119873047\n",
      "---> batch no  150, time taken 0.001993894577026367\n",
      "---> batch no  151, time taken 0.002991199493408203\n",
      "---> batch no  152, time taken 0.0019943714141845703\n",
      "---> batch no  153, time taken 0.001993894577026367\n",
      "---> batch no  154, time taken 0.0029964447021484375\n",
      "---> batch no  155, time taken 0.0029935836791992188\n",
      "---> batch no  156, time taken 0.0029904842376708984\n",
      "---> batch no  157, time taken 0.001993894577026367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> batch no  158, time taken 0.002992391586303711\n",
      "---> batch no  159, time taken 0.001993894577026367\n",
      "---> batch no  160, time taken 0.007977724075317383\n",
      "---> batch no  161, time taken 0.0019943714141845703\n",
      "---> batch no  162, time taken 0.0019948482513427734\n",
      "---> batch no  163, time taken 0.002993345260620117\n",
      "---> batch no  164, time taken 0.0019943714141845703\n",
      "---> batch no  165, time taken 0.0019941329956054688\n",
      "---> batch no  166, time taken 0.0019941329956054688\n",
      "---> batch no  167, time taken 0.0019941329956054688\n",
      "---> batch no  168, time taken 0.002991199493408203\n",
      "---> batch no  169, time taken 0.0029916763305664062\n",
      "---> batch no  170, time taken 0.0019948482513427734\n",
      "---> batch no  171, time taken 0.0019941329956054688\n",
      "---> batch no  172, time taken 0.0019936561584472656\n",
      "---> batch no  173, time taken 0.0029916763305664062\n",
      "---> batch no  174, time taken 0.0019941329956054688\n",
      "---> batch no  175, time taken 0.0019943714141845703\n",
      "---> batch no  176, time taken 0.001994609832763672\n",
      "---> batch no  177, time taken 0.0019943714141845703\n",
      "---> batch no  178, time taken 0.002513885498046875\n",
      "---> batch no  179, time taken 0.0029914379119873047\n",
      "---> batch no  180, time taken 0.001994609832763672\n",
      "---> batch no  181, time taken 0.0019943714141845703\n",
      "---> batch no  182, time taken 0.002991199493408203\n",
      "---> batch no  183, time taken 0.0019941329956054688\n",
      "---> batch no  184, time taken 0.003989696502685547\n",
      "---> batch no  185, time taken 0.0019943714141845703\n",
      "---> batch no  186, time taken 0.0025010108947753906\n",
      "---> batch no  187, time taken 0.001992940902709961\n",
      "---> batch no  188, time taken 0.002991199493408203\n",
      "---> batch no  189, time taken 0.001995086669921875\n",
      "---> batch no  190, time taken 0.001994609832763672\n",
      "---> batch no  191, time taken 0.001993417739868164\n",
      "---> batch no  192, time taken 0.0019936561584472656\n",
      "---> batch no  193, time taken 0.0029921531677246094\n",
      "---> batch no  194, time taken 0.001994609832763672\n",
      "---> batch no  195, time taken 0.0029914379119873047\n",
      "---> batch no  196, time taken 0.002989053726196289\n",
      "---> batch no  197, time taken 0.0029916763305664062\n",
      "---> batch no  198, time taken 0.0029942989349365234\n",
      "---> batch no  199, time taken 0.002992391586303711\n",
      "---> batch no  200, time taken 0.001993894577026367\n",
      "---> batch no  201, time taken 0.002989530563354492\n",
      "---> batch no  202, time taken 0.0019943714141845703\n",
      "---> batch no  203, time taken 0.0029914379119873047\n",
      "---> batch no  204, time taken 0.0029916763305664062\n",
      "---> batch no  205, time taken 0.0019943714141845703\n",
      "---> batch no  206, time taken 0.001993894577026367\n",
      "---> batch no  207, time taken 0.001993894577026367\n",
      "---> batch no  208, time taken 0.0029916763305664062\n",
      "---> batch no  209, time taken 0.0029909610748291016\n",
      "---> batch no  210, time taken 0.001995086669921875\n",
      "---> batch no  211, time taken 0.001994609832763672\n",
      "---> batch no  212, time taken 0.0019943714141845703\n",
      "---> batch no  213, time taken 0.0019948482513427734\n",
      "---> batch no  214, time taken 0.002991914749145508\n",
      "---> batch no  215, time taken 0.002991199493408203\n",
      "---> batch no  216, time taken 0.001994609832763672\n",
      "---> batch no  217, time taken 0.004986286163330078\n",
      "---> batch no  218, time taken 0.002991199493408203\n",
      "---> batch no  219, time taken 0.001993894577026367\n",
      "---> batch no  220, time taken 0.002990245819091797\n",
      "---> batch no  221, time taken 0.001993894577026367\n",
      "---> batch no  222, time taken 0.0029909610748291016\n",
      "---> batch no  223, time taken 0.002989530563354492\n",
      "---> batch no  224, time taken 0.00299072265625\n",
      "---> batch no  225, time taken 0.0019943714141845703\n",
      "---> batch no  226, time taken 0.0029921531677246094\n",
      "---> batch no  227, time taken 0.001994609832763672\n",
      "---> batch no  228, time taken 0.002991199493408203\n",
      "---> batch no  229, time taken 0.0025043487548828125\n",
      "---> batch no  230, time taken 0.0019941329956054688\n",
      "---> batch no  231, time taken 0.0029914379119873047\n",
      "---> batch no  232, time taken 0.0019943714141845703\n",
      "---> batch no  233, time taken 0.002989530563354492\n",
      "---> batch no  234, time taken 0.001994609832763672\n",
      "---> batch no  235, time taken 0.002991914749145508\n",
      "---> batch no  236, time taken 0.0019943714141845703\n",
      "---> batch no  237, time taken 0.001994609832763672\n",
      "---> batch no  238, time taken 0.0019943714141845703\n",
      "---> batch no  239, time taken 0.002991199493408203\n",
      "---> batch no  240, time taken 0.0029916763305664062\n",
      "---> batch no  241, time taken 0.001995563507080078\n",
      "---> batch no  242, time taken 0.0029942989349365234\n",
      "---> batch no  243, time taken 0.001994609832763672\n",
      "---> batch no  244, time taken 0.0019943714141845703\n",
      "---> batch no  245, time taken 0.002991199493408203\n",
      "---> batch no  246, time taken 0.002991914749145508\n",
      "---> batch no  247, time taken 0.003989219665527344\n",
      "---> batch no  248, time taken 0.0019941329956054688\n",
      "---> batch no  249, time taken 0.0019941329956054688\n",
      "---> batch no  250, time taken 0.0029935836791992188\n",
      "---> batch no  251, time taken 0.0019943714141845703\n",
      "---> batch no  252, time taken 0.0019943714141845703\n",
      "---> batch no  253, time taken 0.002991914749145508\n",
      "---> batch no  254, time taken 0.002991914749145508\n",
      "---> batch no  255, time taken 0.001993894577026367\n",
      "---> batch no  256, time taken 0.0019943714141845703\n",
      "---> batch no  257, time taken 0.002498626708984375\n",
      "---> batch no  258, time taken 0.0029914379119873047\n",
      "---> batch no  259, time taken 0.001993894577026367\n",
      "---> batch no  260, time taken 0.0029916763305664062\n",
      "---> batch no  261, time taken 0.0029916763305664062\n",
      "---> batch no  262, time taken 0.001994609832763672\n",
      "---> batch no  263, time taken 0.0019941329956054688\n",
      "---> batch no  264, time taken 0.0029892921447753906\n",
      "---> batch no  265, time taken 0.002991914749145508\n",
      "---> batch no  266, time taken 0.0029909610748291016\n",
      "---> batch no  267, time taken 0.0019941329956054688\n",
      "---> batch no  268, time taken 0.001994609832763672\n",
      "---> batch no  269, time taken 0.0020089149475097656\n",
      "---> batch no  270, time taken 0.002991914749145508\n",
      "---> batch no  271, time taken 0.0029904842376708984\n",
      "---> batch no  272, time taken 0.0029938220977783203\n",
      "---> batch no  273, time taken 0.0029909610748291016\n",
      "---> batch no  274, time taken 0.0029921531677246094\n",
      "---> batch no  275, time taken 0.001993894577026367\n",
      "---> batch no  276, time taken 0.0019943714141845703\n",
      "---> batch no  277, time taken 0.0019941329956054688\n",
      "---> batch no  278, time taken 0.001994609832763672\n",
      "---> batch no  279, time taken 0.0019943714141845703\n",
      "---> batch no  280, time taken 0.00399017333984375\n",
      "---> batch no  281, time taken 0.0019943714141845703\n",
      "---> batch no  282, time taken 0.001993894577026367\n",
      "---> batch no  283, time taken 0.0029892921447753906\n",
      "---> batch no  284, time taken 0.0019943714141845703\n",
      "---> batch no  285, time taken 0.0019941329956054688\n",
      "---> batch no  286, time taken 0.0029938220977783203\n",
      "---> batch no  287, time taken 0.0029916763305664062\n",
      "---> batch no  288, time taken 0.0029916763305664062\n",
      "---> batch no  289, time taken 0.001994609832763672\n",
      "---> batch no  290, time taken 0.0019943714141845703\n",
      "---> batch no  291, time taken 0.0029916763305664062\n",
      "---> batch no  292, time taken 0.002990245819091797\n",
      "---> batch no  293, time taken 0.0019943714141845703\n",
      "---> batch no  294, time taken 0.0029916763305664062\n",
      "---> batch no  295, time taken 0.0019941329956054688\n",
      "---> batch no  296, time taken 0.0029914379119873047\n",
      "---> batch no  297, time taken 0.00299072265625\n",
      "---> batch no  298, time taken 0.0019943714141845703\n",
      "---> batch no  299, time taken 0.0029916763305664062\n",
      "---> batch no  300, time taken 0.00299072265625\n",
      "---> batch no  301, time taken 0.001993894577026367\n",
      "---> batch no  302, time taken 0.0019943714141845703\n",
      "---> batch no  303, time taken 0.0019943714141845703\n",
      "---> batch no  304, time taken 0.0029909610748291016\n",
      "---> batch no  305, time taken 0.0019948482513427734\n",
      "---> batch no  306, time taken 0.0019948482513427734\n",
      "---> batch no  307, time taken 0.0029914379119873047\n",
      "---> batch no  308, time taken 0.0019941329956054688\n",
      "---> batch no  309, time taken 0.002990245819091797\n",
      "---> batch no  310, time taken 0.0019941329956054688\n",
      "---> batch no  311, time taken 0.001994609832763672\n",
      "---> batch no  312, time taken 0.002991914749145508\n",
      "---> batch no  313, time taken 0.0029976367950439453\n",
      "---> batch no  314, time taken 0.002991914749145508\n",
      "---> batch no  315, time taken 0.0029916763305664062\n",
      "---> batch no  316, time taken 0.0019943714141845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> batch no  317, time taken 0.002991199493408203\n",
      "---> batch no  318, time taken 0.001994609832763672\n",
      "---> batch no  319, time taken 0.0019943714141845703\n",
      "---> batch no  320, time taken 0.0019943714141845703\n",
      "---> batch no  321, time taken 0.0019948482513427734\n",
      "---> batch no  322, time taken 0.0019943714141845703\n",
      "---> batch no  323, time taken 0.002992868423461914\n",
      "---> batch no  324, time taken 0.0019943714141845703\n",
      "---> batch no  325, time taken 0.0019941329956054688\n",
      "---> batch no  326, time taken 0.0029754638671875\n",
      "---> batch no  327, time taken 0.0019948482513427734\n",
      "---> batch no  328, time taken 0.0019969940185546875\n",
      "---> batch no  329, time taken 0.001995086669921875\n",
      "---> batch no  330, time taken 0.002991914749145508\n",
      "---> batch no  331, time taken 0.002986431121826172\n",
      "---> batch no  332, time taken 0.0019948482513427734\n",
      "---> batch no  333, time taken 0.001994609832763672\n",
      "---> batch no  334, time taken 0.001995086669921875\n",
      "---> batch no  335, time taken 0.0019941329956054688\n",
      "---> batch no  336, time taken 0.0019943714141845703\n",
      "---> batch no  337, time taken 0.0029916763305664062\n",
      "---> batch no  338, time taken 0.0019941329956054688\n",
      "---> batch no  339, time taken 0.0019941329956054688\n",
      "---> batch no  340, time taken 0.002991199493408203\n",
      "---> batch no  341, time taken 0.002991914749145508\n",
      "---> batch no  342, time taken 0.0019941329956054688\n",
      "---> batch no  343, time taken 0.001993894577026367\n",
      "---> batch no  344, time taken 0.0029916763305664062\n",
      "---> batch no  345, time taken 0.0025055408477783203\n",
      "---> batch no  346, time taken 0.0019941329956054688\n",
      "---> batch no  347, time taken 0.0019943714141845703\n",
      "---> batch no  348, time taken 0.001993894577026367\n",
      "---> batch no  349, time taken 0.0019943714141845703\n",
      "---> batch no  350, time taken 0.002991914749145508\n",
      "---> batch no  351, time taken 0.0019941329956054688\n",
      "---> batch no  352, time taken 0.001994609832763672\n",
      "---> batch no  353, time taken 0.001993894577026367\n",
      "---> batch no  354, time taken 0.0019943714141845703\n",
      "---> batch no  355, time taken 0.0029909610748291016\n",
      "---> batch no  356, time taken 0.0019943714141845703\n",
      "---> batch no  357, time taken 0.001994609832763672\n",
      "---> batch no  358, time taken 0.002991914749145508\n",
      "---> batch no  359, time taken 0.002991914749145508\n",
      "---> batch no  360, time taken 0.0029897689819335938\n",
      "---> batch no  361, time taken 0.0029900074005126953\n",
      "---> batch no  362, time taken 0.0029916763305664062\n",
      "---> batch no  363, time taken 0.0019943714141845703\n",
      "---> batch no  364, time taken 0.0019941329956054688\n",
      "---> batch no  365, time taken 0.0029959678649902344\n",
      "---> batch no  366, time taken 0.002991914749145508\n",
      "---> batch no  367, time taken 0.0029909610748291016\n",
      "---> batch no  368, time taken 0.0029900074005126953\n",
      "---> batch no  369, time taken 0.0029914379119873047\n",
      "---> batch no  370, time taken 0.0029909610748291016\n",
      "---> batch no  371, time taken 0.0019941329956054688\n",
      "---> batch no  372, time taken 0.002991914749145508\n",
      "---> batch no  373, time taken 0.0019936561584472656\n",
      "---> batch no  374, time taken 0.0029914379119873047\n",
      "---> batch no  375, time taken 0.0019943714141845703\n",
      "---> batch no  376, time taken 0.0029916763305664062\n",
      "---> batch no  377, time taken 0.001993894577026367\n",
      "---> batch no  378, time taken 0.001994609832763672\n",
      "---> batch no  379, time taken 0.0029916763305664062\n",
      "---> batch no  380, time taken 0.0019936561584472656\n",
      "---> batch no  381, time taken 0.0029904842376708984\n",
      "---> batch no  382, time taken 0.0019943714141845703\n",
      "---> batch no  383, time taken 0.001993894577026367\n",
      "---> batch no  384, time taken 0.0029916763305664062\n",
      "---> batch no  385, time taken 0.0019941329956054688\n",
      "---> batch no  386, time taken 0.001994609832763672\n",
      "---> batch no  387, time taken 0.0019943714141845703\n",
      "---> batch no  388, time taken 0.0019941329956054688\n",
      "---> batch no  389, time taken 0.0029916763305664062\n",
      "---> batch no  390, time taken 0.0029914379119873047\n",
      "---> batch no  391, time taken 0.0019943714141845703\n",
      "---> batch no  392, time taken 0.002991199493408203\n",
      "---> batch no  393, time taken 0.0019943714141845703\n",
      "---> batch no  394, time taken 0.0029926300048828125\n",
      "---> batch no  395, time taken 0.0019941329956054688\n",
      "---> batch no  396, time taken 0.0019941329956054688\n",
      "---> batch no  397, time taken 0.0029904842376708984\n",
      "---> batch no  398, time taken 0.0029921531677246094\n",
      "---> batch no  399, time taken 0.002991914749145508\n",
      "---> batch no  400, time taken 0.0019943714141845703\n",
      "---> batch no  401, time taken 0.0029914379119873047\n",
      "---> batch no  402, time taken 0.002502918243408203\n",
      "---> batch no  403, time taken 0.0029916763305664062\n",
      "---> batch no  404, time taken 0.0029916763305664062\n",
      "---> batch no  405, time taken 0.0029931068420410156\n",
      "---> batch no  406, time taken 0.0019941329956054688\n",
      "---> batch no  407, time taken 0.0029914379119873047\n",
      "---> batch no  408, time taken 0.0029914379119873047\n",
      "---> batch no  409, time taken 0.0019941329956054688\n",
      "---> batch no  410, time taken 0.0019943714141845703\n",
      "---> batch no  411, time taken 0.001994609832763672\n",
      "---> batch no  412, time taken 0.002991199493408203\n",
      "---> batch no  413, time taken 0.002991914749145508\n",
      "---> batch no  414, time taken 0.002992868423461914\n",
      "---> batch no  415, time taken 0.001993894577026367\n",
      "---> batch no  416, time taken 0.0019941329956054688\n",
      "---> batch no  417, time taken 0.001994609832763672\n",
      "---> batch no  418, time taken 0.0019943714141845703\n",
      "---> batch no  419, time taken 0.002003192901611328\n",
      "---> batch no  420, time taken 0.0019941329956054688\n",
      "---> batch no  421, time taken 0.0019941329956054688\n",
      "---> batch no  422, time taken 0.002996206283569336\n",
      "---> batch no  423, time taken 0.0019948482513427734\n",
      "---> batch no  424, time taken 0.0020012855529785156\n",
      "---> batch no  425, time taken 0.0019941329956054688\n",
      "---> batch no  426, time taken 0.0019943714141845703\n",
      "---> batch no  427, time taken 0.001995086669921875\n",
      "---> batch no  428, time taken 0.0019941329956054688\n",
      "---> batch no  429, time taken 0.001994609832763672\n",
      "---> batch no  430, time taken 0.0029916763305664062\n",
      "---> batch no  431, time taken 0.001994609832763672\n",
      "---> batch no  432, time taken 0.0029921531677246094\n",
      "---> batch no  433, time taken 0.0029914379119873047\n",
      "---> batch no  434, time taken 0.0019943714141845703\n",
      "---> batch no  435, time taken 0.002989053726196289\n",
      "---> batch no  436, time taken 0.0029914379119873047\n",
      "---> batch no  437, time taken 0.0029909610748291016\n",
      "---> batch no  438, time taken 0.0019943714141845703\n",
      "---> batch no  439, time taken 0.0059833526611328125\n",
      "---> batch no  440, time taken 0.0019941329956054688\n",
      "---> batch no  441, time taken 0.0029914379119873047\n",
      "---> batch no  442, time taken 0.0029900074005126953\n",
      "---> batch no  443, time taken 0.0029897689819335938\n",
      "---> batch no  444, time taken 0.0019943714141845703\n",
      "---> batch no  445, time taken 0.0019943714141845703\n",
      "---> batch no  446, time taken 0.0019943714141845703\n",
      "---> batch no  447, time taken 0.00299072265625\n",
      "---> batch no  448, time taken 0.001993894577026367\n",
      "---> batch no  449, time taken 0.0029914379119873047\n",
      "---> batch no  450, time taken 0.0019943714141845703\n",
      "---> batch no  451, time taken 0.002991199493408203\n",
      "---> batch no  452, time taken 0.0029904842376708984\n",
      "---> batch no  453, time taken 0.0029921531677246094\n",
      "---> batch no  454, time taken 0.001994609832763672\n",
      "---> batch no  455, time taken 0.00299072265625\n",
      "---> batch no  456, time taken 0.0039882659912109375\n",
      "---> batch no  457, time taken 0.0024995803833007812\n",
      "---> batch no  458, time taken 0.002990245819091797\n",
      "---> batch no  459, time taken 0.002991914749145508\n",
      "---> batch no  460, time taken 0.0029909610748291016\n",
      "---> batch no  461, time taken 0.0029909610748291016\n",
      "---> batch no  462, time taken 0.002992391586303711\n",
      "---> batch no  463, time taken 0.002991199493408203\n",
      "---> batch no  464, time taken 0.002987384796142578\n",
      "---> batch no  465, time taken 0.0029926300048828125\n",
      "---> batch no  466, time taken 0.002990245819091797\n",
      "---> batch no  467, time taken 0.0029916763305664062\n",
      "---> batch no  468, time taken 0.001993894577026367\n",
      "---> batch no  469, time taken 0.0029916763305664062\n",
      "---> batch no  470, time taken 0.0019943714141845703\n",
      "---> batch no  471, time taken 0.001995086669921875\n",
      "---> batch no  472, time taken 0.0029990673065185547\n",
      "---> batch no  473, time taken 0.0029914379119873047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> batch no  474, time taken 0.002991914749145508\n",
      "---> batch no  475, time taken 0.0019943714141845703\n",
      "---> batch no  476, time taken 0.001993894577026367\n",
      "---> batch no  477, time taken 0.0019941329956054688\n",
      "---> batch no  478, time taken 0.0019943714141845703\n",
      "---> batch no  479, time taken 0.001993894577026367\n",
      "---> batch no  480, time taken 0.0019943714141845703\n",
      "---> batch no  481, time taken 0.001994609832763672\n",
      "---> batch no  482, time taken 0.001993417739868164\n",
      "---> batch no  483, time taken 0.0019943714141845703\n",
      "---> batch no  484, time taken 0.001994609832763672\n",
      "---> batch no  485, time taken 0.0029914379119873047\n",
      "---> batch no  486, time taken 0.001993894577026367\n",
      "---> batch no  487, time taken 0.0029900074005126953\n",
      "---> batch no  488, time taken 0.002991199493408203\n",
      "---> batch no  489, time taken 0.002991914749145508\n",
      "---> batch no  490, time taken 0.0019948482513427734\n",
      "---> batch no  491, time taken 0.003988504409790039\n",
      "---> batch no  492, time taken 0.002991914749145508\n",
      "---> batch no  493, time taken 0.0019943714141845703\n",
      "---> batch no  494, time taken 0.0019941329956054688\n",
      "---> batch no  495, time taken 0.001994609832763672\n",
      "---> batch no  496, time taken 0.0019943714141845703\n",
      "---> batch no  497, time taken 0.002992868423461914\n",
      "---> batch no  498, time taken 0.0029914379119873047\n",
      "---> batch no  499, time taken 0.0029909610748291016\n",
      "---> batch no  500, time taken 0.0019943714141845703\n",
      "---> batch no  501, time taken 0.0019943714141845703\n",
      "---> batch no  502, time taken 0.0019941329956054688\n",
      "---> batch no  503, time taken 0.002991199493408203\n",
      "---> batch no  504, time taken 0.001994609832763672\n",
      "---> batch no  505, time taken 0.0029914379119873047\n",
      "---> batch no  506, time taken 0.0029926300048828125\n",
      "---> batch no  507, time taken 0.0019943714141845703\n",
      "---> batch no  508, time taken 0.0029914379119873047\n",
      "---> batch no  509, time taken 0.0029914379119873047\n",
      "---> batch no  510, time taken 0.0029916763305664062\n",
      "---> batch no  511, time taken 0.002001523971557617\n",
      "---> batch no  512, time taken 0.0029914379119873047\n",
      "---> batch no  513, time taken 0.0019941329956054688\n",
      "---> batch no  514, time taken 0.0029921531677246094\n",
      "---> batch no  515, time taken 0.0029897689819335938\n",
      "---> batch no  516, time taken 0.002992868423461914\n",
      "---> batch no  517, time taken 0.0019941329956054688\n",
      "---> batch no  518, time taken 0.002991914749145508\n",
      "---> batch no  519, time taken 0.0019948482513427734\n",
      "---> batch no  520, time taken 0.0029921531677246094\n",
      "---> batch no  521, time taken 0.002991914749145508\n",
      "---> batch no  522, time taken 0.0029921531677246094\n",
      "---> batch no  523, time taken 0.002991914749145508\n",
      "---> batch no  524, time taken 0.002991199493408203\n",
      "---> batch no  525, time taken 0.0019948482513427734\n",
      "---> batch no  526, time taken 0.0029909610748291016\n",
      "---> batch no  527, time taken 0.0019943714141845703\n",
      "---> batch no  528, time taken 0.0019943714141845703\n",
      "---> batch no  529, time taken 0.0029914379119873047\n",
      "---> batch no  530, time taken 0.0019953250885009766\n",
      "---> batch no  531, time taken 0.0019943714141845703\n",
      "---> batch no  532, time taken 0.001994609832763672\n",
      "---> batch no  533, time taken 0.0019941329956054688\n",
      "---> batch no  534, time taken 0.0029916763305664062\n",
      "---> batch no  535, time taken 0.0029916763305664062\n",
      "---> batch no  536, time taken 0.001995086669921875\n",
      "---> batch no  537, time taken 0.0029914379119873047\n",
      "---> batch no  538, time taken 0.001992940902709961\n",
      "pass 0 time taken 22.932637691497803\n"
     ]
    }
   ],
   "source": [
    "for x in range(1):\n",
    "    start = time.time()\n",
    "    for i,data in enumerate(TRAIN_LOADER):\n",
    "        load_start = time.time()\n",
    "        image, label = data\n",
    "        print(\"---> batch no  {}, time taken {}\".format(i, time.time()-load_start ))\n",
    "    print(\"pass {} time taken {}\".format(x, -start + time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs:int):\n",
    "    all_training_losses = []\n",
    "    all_training_accuracy = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_epoch_loss = 0\n",
    "        total_accuracy_epoch = 0\n",
    "        for i, data in tqdm(enumerate(TRAIN_LOADER, 0)): \n",
    "            image,label = data\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            label = label.to(DEVICE)\n",
    "            image = image.to(DEVICE)\n",
    "            output = net(image)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                total_epoch_loss += loss\n",
    "                batches_training_accuracy = accuracy_finder(predictions=output, labels=label)\n",
    "                total_accuracy_epoch = total_accuracy_epoch  + batches_training_accuracy   \n",
    "            \n",
    "            if i % 1000 == 0: \n",
    "               print(\"Batch : {}/{}\".format(i, len(TRAIN_LOADER))) \n",
    "        # total epoch loss \n",
    "        total_epoch_loss = total_epoch_loss / len(TRAIN_LOADER)\n",
    "        # total epoch accuracy \n",
    "        total_accuracy_epoch = total_accuracy_epoch /len(TRAIN_LOADER)\n",
    "        \n",
    "        # display the epoch training loss\n",
    "        print(\"epoch : {}/{}, loss = {:.8f}, acc = {:.8f}\".format(epoch + 1, epochs, total_epoch_loss, total_accuracy_epoch ))\n",
    "        all_training_losses.append(total_epoch_loss)\n",
    "        all_training_accuracy.append(total_accuracy_epoch)\n",
    "        \n",
    "    print(\"Training completed\")\n",
    "    return all_training_accuracy, all_training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_acc, t_loss = training(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
