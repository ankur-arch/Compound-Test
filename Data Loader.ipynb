{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = pd.read_csv(\"./CMATERdbTrain.csv\", usecols=[\"labels\",\"directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000000.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000032.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000033.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000034.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000035.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTrain\\156\\bcc001573.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTrain\\156\\bcc001574.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTrain\\156\\bcc001572.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>158</td>\n",
       "      <td>dataset\\CMATERdbTrain\\158\\bcc001575.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>159</td>\n",
       "      <td>dataset\\CMATERdbTrain\\159\\bcc001576.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                directory\n",
       "0          1    dataset\\CMATERdbTrain\\1\\bcc000000.bmp\n",
       "1          1    dataset\\CMATERdbTrain\\1\\bcc000032.bmp\n",
       "2          1    dataset\\CMATERdbTrain\\1\\bcc000033.bmp\n",
       "3          1    dataset\\CMATERdbTrain\\1\\bcc000034.bmp\n",
       "4          1    dataset\\CMATERdbTrain\\1\\bcc000035.bmp\n",
       "...      ...                                      ...\n",
       "1572     156  dataset\\CMATERdbTrain\\156\\bcc001573.bmp\n",
       "1573     156  dataset\\CMATERdbTrain\\156\\bcc001574.bmp\n",
       "1574     156  dataset\\CMATERdbTrain\\156\\bcc001572.bmp\n",
       "1575     158  dataset\\CMATERdbTrain\\158\\bcc001575.bmp\n",
       "1576     159  dataset\\CMATERdbTrain\\159\\bcc001576.bmp\n",
       "\n",
       "[1577 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data = pd.read_csv(\"./CMATERdbTest.csv\", usecols=[\"labels\",\"directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000000.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000014.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000012.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000011.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000010.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>155</td>\n",
       "      <td>dataset\\CMATERdbTest\\155\\bcc000467.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTest\\156\\bcc000468.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>158</td>\n",
       "      <td>dataset\\CMATERdbTest\\158\\bcc000469.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>159</td>\n",
       "      <td>dataset\\CMATERdbTest\\159\\bcc000470.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>166</td>\n",
       "      <td>dataset\\CMATERdbTest\\166\\bcc000471.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                               directory\n",
       "0         1    dataset\\CMATERdbTest\\1\\bcc000000.bmp\n",
       "1         1    dataset\\CMATERdbTest\\1\\bcc000014.bmp\n",
       "2         1    dataset\\CMATERdbTest\\1\\bcc000012.bmp\n",
       "3         1    dataset\\CMATERdbTest\\1\\bcc000011.bmp\n",
       "4         1    dataset\\CMATERdbTest\\1\\bcc000010.bmp\n",
       "..      ...                                     ...\n",
       "467     155  dataset\\CMATERdbTest\\155\\bcc000467.bmp\n",
       "468     156  dataset\\CMATERdbTest\\156\\bcc000468.bmp\n",
       "469     158  dataset\\CMATERdbTest\\158\\bcc000469.bmp\n",
       "470     159  dataset\\CMATERdbTest\\159\\bcc000470.bmp\n",
       "471     166  dataset\\CMATERdbTest\\166\\bcc000471.bmp\n",
       "\n",
       "[472 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n"
     ]
    }
   ],
   "source": [
    "nuTest = Test_Data.to_numpy()\n",
    "print(len(nuTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset\\\\CMATERdbTest\\\\1\\\\bcc000000.bmp'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Data.to_numpy()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sk.imread(Test_Data.to_numpy()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 109, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 149, 109])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = t(image)\n",
    "t_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_image = torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([149, 109, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts = torch_image.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 149, 109])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompundCharacterDataset(Dataset):\n",
    "    def __init__(self, csv_dir_path,  transforms=None):\n",
    "        ### numpy array for entire dataset\n",
    "        self.dataset = pd.read_csv(csv_dir_path, usecols=[\"labels\",\"directory\"]).to_numpy()  \n",
    "        \n",
    "        ### labels\n",
    "        self.labels = self.dataset[:,0]\n",
    "        #print(self.labels)\n",
    "        ### images\n",
    "        self.images = self.dataset[:,1]\n",
    "        #print(self.images)\n",
    "        \n",
    "        ### transformations to apply on images\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        label = torch.tensor(self.labels[index])\n",
    "        image_dir = self.images[index]\n",
    "        #print(self.images)\n",
    "        image = sk.imread(os.path.join(os.getcwd(),image_dir))\n",
    "        image = resize(image, (100, 100, 3))\n",
    "        reshaped_image = image\n",
    "        if self.transforms:\n",
    "            reshaped_image = self.transforms(reshaped_image)\n",
    "        return reshaped_image,label \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET = CompundCharacterDataset(csv_dir_path=\"./CMATERdbTest.csv\",transforms=transforms.ToTensor())\n",
    "TEST_LOADER = DataLoader(dataset=TEST_DATASET, batch_size=BATCH_SIZE, shuffle= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = CompundCharacterDataset(csv_dir_path=\"./CMATERdbTrain.csv\",transforms=transforms.ToTensor())\n",
    "TRAIN_LOADER = DataLoader(dataset=TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2500, out_features=159, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_layers =  nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            # in_channels (int) – Number of channels in the input image. For B&W it is 1.\n",
    "            # out_channels (int) – Number of channels produced by the convolution. 4 filters\n",
    "            # kernel_size (int or tuple) – Size of the convolving kernel (3x3)\n",
    "            # stride (int or tuple, optional) – Stride of the convolution\n",
    "            # padding (int or tuple, optional) – Padding of 1 added to both sides of the input\n",
    "            # example x1 = (n, c=3 , h=100 , w=100 )\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1), #in_channels = 1 is a data dependent hyperparameter. It is 1 because the images are in grayscale\n",
    "            # x2 = (n, c=12 , h=100 , w=100 )\n",
    "            nn.BatchNorm2d(4), # Normalize output from the activation function. \n",
    "            nn.ReLU(inplace=True), # negative elements to zero\n",
    "            # x2 = (n, c=12 , h=100 , w=100 )\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #Stride is the number of pixels shifts over the input matrix. When the stride is 1 then we move the filters to 1 pixel at a time. When the stride is 2 then we move the filters to 2 pixels at a time and so on\n",
    "            # x3 = (n, c=12 , h=49 , w=49 )\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            # x3 = (n, c=4 , h=49 , w=49 )\n",
    "            nn.BatchNorm2d(4), # 4 features\n",
    "            nn.ReLU(inplace=True), # inplace = True will modify the input directly, without allocating any additional output.\n",
    "            # x3 = (n, c=48 , h=49 , w=49 )\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Downsamples the input representation by taking the maximum value\n",
    "            # x4 = (n, c=48 , h=25 , w=25 )\n",
    "        )\n",
    "        # outputSize = floor[(inputSize - filterSize + 2 * padding) / stride] + 1\n",
    "print(cnn_layers)\n",
    "\n",
    "\n",
    "linear_layers = nn.Sequential(\n",
    "            nn.Linear(4 * 25 * 25, 159) \n",
    "#159 classes are available for the compound classes dataset. It is a data dependent hyperparameter\n",
    ")\n",
    "\n",
    "print(linear_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn_layer = cnn_layers\n",
    "        self.linear_layer = linear_layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "optimizer =  optim.Adam(net.parameters(), lr=0.07) # learning rate \n",
    "# defining the loss function\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "# change loss function \n",
    "# 1. cross entropy \n",
    "# 2. 1 / (1 + distance between winning prob and second best prob)\n",
    "# add 1 and 2 \n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda is available')\n",
    "    #net = net.cuda()\n",
    "    #criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_finder(predictions , labels):\n",
    "    softmax = torch.nn.Softmax(dim=1) \n",
    "    predictions = softmax(predictions)\n",
    "    values, max_indices = torch.max(predictions, dim=1) \n",
    "    accuracy = ( max_indices == labels ).sum()/max_indices.size()[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs:int , withCustomLoss = False):\n",
    "    all_training_losses = []\n",
    "    all_training_acc = []\n",
    "    min_loss_at_epoch = -1\n",
    "    global_min_average_loss = torch.tensor(999999999)\n",
    "    # min average training loss = infinity \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        targets = []\n",
    "        total_loss_epoch = 0\n",
    "        total_acc_epoch = 0\n",
    "        batches_traversed = 0 \n",
    "        for i, data in enumerate(TRAIN_LOADER, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float() \n",
    "            #if torch.cuda.is_available():\n",
    "            #    inputs = inputs.cuda()\n",
    "            #    labels = labels.cuda()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            print(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            targets.append(labels)\n",
    "            total_loss_epoch = total_loss_epoch + loss\n",
    "            training_accuracy = accuracy_finder(predictions=outputs, labels=labels)\n",
    "            total_acc_epoch = total_acc_epoch + training_accuracy\n",
    "            batches_traversed = batches_traversed + 1 \n",
    "        all_training_losses.append(total_loss_epoch/batches_traversed)\n",
    "        all_training_acc.append(total_acc_epoch/batches_traversed)\n",
    "        \n",
    "        #print(\"epoch : {}, training loss : {}, training accuracy {}\".format(epoch+1,((total_loss_epoch/batches_traversed)),((total_acc_epoch/batches_traversed))))\n",
    "        #save the model with minimum training loss\n",
    "        avg_training_loss_per_epoch = total_loss_epoch/batches_traversed\n",
    "        # if min average training loss > avg_training_loss : min average training loss = avg_training_loss\n",
    "        # save the model \n",
    "        \n",
    "    print('Finished Training')\n",
    "    return (all_training_losses, all_training_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4492, -0.3484, -0.3932,  ..., -2.5155, -2.4861, -2.4941],\n",
      "        [-2.4492, -0.3484, -0.3932,  ..., -2.5155, -2.4861, -2.4941],\n",
      "        [-2.4492, -0.3484, -0.3932,  ..., -2.5155, -2.4861, -2.4941],\n",
      "        ...,\n",
      "        [-2.4492, -0.3484, -0.3932,  ..., -2.5155, -2.4861, -2.4941],\n",
      "        [-2.4492, -0.3484, -0.3932,  ..., -2.5155, -2.4861, -2.4941],\n",
      "        [-2.4492, -0.3484, -0.3932,  ..., -2.5155, -2.4861, -2.4941]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5061, -0.3301, -0.3980,  ..., -2.5725, -2.5432, -2.5511],\n",
      "        [-2.5061, -0.3301, -0.3980,  ..., -2.5725, -2.5432, -2.5511],\n",
      "        [-2.5061, -0.3301, -0.3980,  ..., -2.5725, -2.5432, -2.5511],\n",
      "        ...,\n",
      "        [-2.5061, -0.3301, -0.3980,  ..., -2.5725, -2.5432, -2.5511],\n",
      "        [-2.5061, -0.3301, -0.3980,  ..., -2.5725, -2.5432, -2.5511],\n",
      "        [-2.5061, -0.3301, -0.3980,  ..., -2.5725, -2.5432, -2.5511]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5616, -0.3004, -0.3949,  ..., -2.6281, -2.5988, -2.6067],\n",
      "        [-2.5616, -0.3004, -0.3949,  ..., -2.6281, -2.5988, -2.6067],\n",
      "        [-2.5616, -0.3004, -0.3949,  ..., -2.6281, -2.5988, -2.6067],\n",
      "        ...,\n",
      "        [-2.5616, -0.3004, -0.3949,  ..., -2.6281, -2.5988, -2.6067],\n",
      "        [-2.5616, -0.3004, -0.3949,  ..., -2.6281, -2.5988, -2.6067],\n",
      "        [-2.5616, -0.3004, -0.3949,  ..., -2.6281, -2.5988, -2.6067]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6157, -0.2739, -0.3730,  ..., -2.6823, -2.6530, -2.6608],\n",
      "        [-2.6157, -0.2739, -0.3730,  ..., -2.6823, -2.6530, -2.6608],\n",
      "        [-2.6157, -0.2739, -0.3730,  ..., -2.6823, -2.6530, -2.6608],\n",
      "        ...,\n",
      "        [-2.6157, -0.2739, -0.3730,  ..., -2.6823, -2.6530, -2.6608],\n",
      "        [-2.6157, -0.2739, -0.3730,  ..., -2.6823, -2.6530, -2.6608],\n",
      "        [-2.6157, -0.2739, -0.3730,  ..., -2.6823, -2.6530, -2.6608]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6684, -0.2503, -0.3497,  ..., -2.7351, -2.7057, -2.7135],\n",
      "        [-2.6684, -0.2503, -0.3497,  ..., -2.7351, -2.7057, -2.7135],\n",
      "        [-2.6684, -0.2503, -0.3497,  ..., -2.7351, -2.7057, -2.7135],\n",
      "        ...,\n",
      "        [-2.6684, -0.2503, -0.3497,  ..., -2.7351, -2.7057, -2.7135],\n",
      "        [-2.6684, -0.2503, -0.3497,  ..., -2.7351, -2.7057, -2.7135],\n",
      "        [-2.6684, -0.2503, -0.3497,  ..., -2.7351, -2.7057, -2.7135]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.7197, -0.2294, -0.3289,  ..., -2.7864, -2.7571, -2.7649],\n",
      "        [-2.7197, -0.2294, -0.3289,  ..., -2.7864, -2.7571, -2.7649],\n",
      "        [-2.7197, -0.2294, -0.3289,  ..., -2.7864, -2.7571, -2.7649],\n",
      "        ...,\n",
      "        [-2.7197, -0.2294, -0.3289,  ..., -2.7864, -2.7571, -2.7649],\n",
      "        [-2.7197, -0.2294, -0.3289,  ..., -2.7864, -2.7571, -2.7649],\n",
      "        [-2.7197, -0.2294, -0.3289,  ..., -2.7864, -2.7571, -2.7649]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.7696, -0.2110, -0.3105,  ..., -2.8364, -2.8071, -2.8149],\n",
      "        [-2.7696, -0.2110, -0.3105,  ..., -2.8364, -2.8071, -2.8149],\n",
      "        [-2.7696, -0.2110, -0.3105,  ..., -2.8364, -2.8071, -2.8149],\n",
      "        ...,\n",
      "        [-2.7696, -0.2110, -0.3105,  ..., -2.8364, -2.8071, -2.8149],\n",
      "        [-2.7696, -0.2110, -0.3105,  ..., -2.8364, -2.8071, -2.8149],\n",
      "        [-2.7696, -0.2110, -0.3105,  ..., -2.8364, -2.8071, -2.8149]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.8182, -0.1949, -0.2942,  ..., -2.8850, -2.8557, -2.8635],\n",
      "        [-2.8182, -0.1949, -0.2942,  ..., -2.8850, -2.8557, -2.8635],\n",
      "        [-2.8182, -0.1949, -0.2942,  ..., -2.8850, -2.8557, -2.8635],\n",
      "        ...,\n",
      "        [-2.8182, -0.1949, -0.2942,  ..., -2.8850, -2.8557, -2.8635],\n",
      "        [-2.8182, -0.1949, -0.2942,  ..., -2.8850, -2.8557, -2.8635],\n",
      "        [-2.8182, -0.1949, -0.2942,  ..., -2.8850, -2.8557, -2.8635]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.8654, -0.1808, -0.2799,  ..., -2.9323, -2.9030, -2.9107],\n",
      "        [-2.8654, -0.1808, -0.2799,  ..., -2.9323, -2.9030, -2.9107],\n",
      "        [-2.8654, -0.1808, -0.2799,  ..., -2.9323, -2.9030, -2.9107],\n",
      "        ...,\n",
      "        [-2.8654, -0.1808, -0.2799,  ..., -2.9323, -2.9030, -2.9107],\n",
      "        [-2.8654, -0.1808, -0.2799,  ..., -2.9323, -2.9030, -2.9107],\n",
      "        [-2.8654, -0.1808, -0.2799,  ..., -2.9323, -2.9030, -2.9107]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.9113, -0.1687, -0.2674,  ..., -2.9783, -2.9490, -2.9567],\n",
      "        [-2.9113, -0.1687, -0.2674,  ..., -2.9783, -2.9490, -2.9567],\n",
      "        [-2.9113, -0.1687, -0.2674,  ..., -2.9783, -2.9490, -2.9567],\n",
      "        ...,\n",
      "        [-2.9113, -0.1687, -0.2674,  ..., -2.9783, -2.9490, -2.9567],\n",
      "        [-2.9113, -0.1687, -0.2674,  ..., -2.9783, -2.9490, -2.9567],\n",
      "        [-2.9113, -0.1687, -0.2674,  ..., -2.9783, -2.9490, -2.9567]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.9560, -0.1583, -0.2566,  ..., -3.0229, -2.9936, -3.0014],\n",
      "        [-2.9560, -0.1583, -0.2566,  ..., -3.0229, -2.9936, -3.0014],\n",
      "        [-2.9560, -0.1583, -0.2566,  ..., -3.0229, -2.9936, -3.0014],\n",
      "        ...,\n",
      "        [-2.9560, -0.1583, -0.2566,  ..., -3.0229, -2.9936, -3.0014],\n",
      "        [-2.9560, -0.1583, -0.2566,  ..., -3.0229, -2.9936, -3.0014],\n",
      "        [-2.9560, -0.1583, -0.2566,  ..., -3.0229, -2.9936, -3.0014]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.9994, -0.1496, -0.2472,  ..., -3.0664, -3.0371, -3.0448],\n",
      "        [-2.9994, -0.1496, -0.2472,  ..., -3.0664, -3.0371, -3.0448],\n",
      "        [-2.9994, -0.1496, -0.2472,  ..., -3.0664, -3.0371, -3.0448],\n",
      "        ...,\n",
      "        [-2.9994, -0.1496, -0.2472,  ..., -3.0664, -3.0371, -3.0448],\n",
      "        [-2.9994, -0.1496, -0.2472,  ..., -3.0664, -3.0371, -3.0448],\n",
      "        [-2.9994, -0.1496, -0.2472,  ..., -3.0664, -3.0371, -3.0448]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.0416, -0.1423, -0.2393,  ..., -3.1086, -3.0792, -3.0870],\n",
      "        [-3.0416, -0.1423, -0.2393,  ..., -3.1086, -3.0792, -3.0870],\n",
      "        [-3.0416, -0.1423, -0.2393,  ..., -3.1086, -3.0792, -3.0870],\n",
      "        ...,\n",
      "        [-3.0416, -0.1423, -0.2393,  ..., -3.1086, -3.0792, -3.0870],\n",
      "        [-3.0416, -0.1423, -0.2393,  ..., -3.1086, -3.0792, -3.0870],\n",
      "        [-3.0416, -0.1423, -0.2393,  ..., -3.1086, -3.0792, -3.0870]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.0826, -0.1365, -0.2327,  ..., -3.1496, -3.1202, -3.1280],\n",
      "        [-3.0826, -0.1365, -0.2327,  ..., -3.1496, -3.1202, -3.1280],\n",
      "        [-3.0826, -0.1365, -0.2327,  ..., -3.1496, -3.1202, -3.1280],\n",
      "        ...,\n",
      "        [-3.0826, -0.1365, -0.2327,  ..., -3.1496, -3.1202, -3.1280],\n",
      "        [-3.0826, -0.1365, -0.2327,  ..., -3.1496, -3.1202, -3.1280],\n",
      "        [-3.0826, -0.1365, -0.2327,  ..., -3.1496, -3.1202, -3.1280]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.1225, -0.1318, -0.2273,  ..., -3.1894, -3.1601, -3.1678],\n",
      "        [-3.1225, -0.1318, -0.2273,  ..., -3.1894, -3.1601, -3.1678],\n",
      "        [-3.1225, -0.1318, -0.2273,  ..., -3.1894, -3.1601, -3.1678],\n",
      "        ...,\n",
      "        [-3.1225, -0.1318, -0.2273,  ..., -3.1894, -3.1601, -3.1678],\n",
      "        [-3.1225, -0.1318, -0.2273,  ..., -3.1894, -3.1601, -3.1678],\n",
      "        [-3.1225, -0.1318, -0.2273,  ..., -3.1894, -3.1601, -3.1678]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.1612, -0.1284, -0.2229,  ..., -3.2281, -3.1988, -3.2065],\n",
      "        [-3.1612, -0.1284, -0.2229,  ..., -3.2281, -3.1988, -3.2065],\n",
      "        [-3.1612, -0.1284, -0.2229,  ..., -3.2281, -3.1988, -3.2065],\n",
      "        ...,\n",
      "        [-3.1612, -0.1284, -0.2229,  ..., -3.2281, -3.1988, -3.2065],\n",
      "        [-3.1612, -0.1284, -0.2229,  ..., -3.2281, -3.1988, -3.2065],\n",
      "        [-3.1612, -0.1284, -0.2229,  ..., -3.2281, -3.1988, -3.2065]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.1988, -0.1259, -0.2195,  ..., -3.2657, -3.2364, -3.2441],\n",
      "        [-3.1988, -0.1259, -0.2195,  ..., -3.2657, -3.2364, -3.2441],\n",
      "        [-3.1988, -0.1259, -0.2195,  ..., -3.2657, -3.2364, -3.2441],\n",
      "        ...,\n",
      "        [-3.1988, -0.1259, -0.2195,  ..., -3.2657, -3.2364, -3.2441],\n",
      "        [-3.1988, -0.1259, -0.2195,  ..., -3.2657, -3.2364, -3.2441],\n",
      "        [-3.1988, -0.1259, -0.2195,  ..., -3.2657, -3.2364, -3.2441]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.2353, -0.1245, -0.2170,  ..., -3.3022, -3.2729, -3.2807],\n",
      "        [-3.2353, -0.1245, -0.2170,  ..., -3.3022, -3.2729, -3.2807],\n",
      "        [-3.2353, -0.1245, -0.2170,  ..., -3.3022, -3.2729, -3.2807],\n",
      "        ...,\n",
      "        [-3.2353, -0.1245, -0.2170,  ..., -3.3022, -3.2729, -3.2807],\n",
      "        [-3.2353, -0.1245, -0.2170,  ..., -3.3022, -3.2729, -3.2807],\n",
      "        [-3.2353, -0.1245, -0.2170,  ..., -3.3022, -3.2729, -3.2807]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.2708, -0.1239, -0.2154,  ..., -3.3377, -3.3084, -3.3162],\n",
      "        [-3.2708, -0.1239, -0.2154,  ..., -3.3377, -3.3084, -3.3162],\n",
      "        [-3.2708, -0.1239, -0.2154,  ..., -3.3377, -3.3084, -3.3162],\n",
      "        ...,\n",
      "        [-3.2708, -0.1239, -0.2154,  ..., -3.3377, -3.3084, -3.3162],\n",
      "        [-3.2708, -0.1239, -0.2154,  ..., -3.3377, -3.3084, -3.3162],\n",
      "        [-3.2708, -0.1239, -0.2154,  ..., -3.3377, -3.3084, -3.3162]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.3054, -0.1242, -0.2145,  ..., -3.3722, -3.3429, -3.3507],\n",
      "        [-3.3054, -0.1242, -0.2145,  ..., -3.3722, -3.3429, -3.3507],\n",
      "        [-3.3054, -0.1242, -0.2145,  ..., -3.3722, -3.3429, -3.3507],\n",
      "        ...,\n",
      "        [-3.3054, -0.1242, -0.2145,  ..., -3.3722, -3.3429, -3.3507],\n",
      "        [-3.3054, -0.1242, -0.2145,  ..., -3.3722, -3.3429, -3.3507],\n",
      "        [-3.3054, -0.1242, -0.2145,  ..., -3.3722, -3.3429, -3.3507]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.3389, -0.1252, -0.2143,  ..., -3.4057, -3.3764, -3.3842],\n",
      "        [-3.3389, -0.1252, -0.2143,  ..., -3.4057, -3.3764, -3.3842],\n",
      "        [-3.3389, -0.1252, -0.2143,  ..., -3.4057, -3.3764, -3.3842],\n",
      "        ...,\n",
      "        [-3.3389, -0.1252, -0.2143,  ..., -3.4057, -3.3764, -3.3842],\n",
      "        [-3.3389, -0.1252, -0.2143,  ..., -3.4057, -3.3764, -3.3842],\n",
      "        [-3.3389, -0.1252, -0.2143,  ..., -3.4057, -3.3764, -3.3842]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.3716, -0.1269, -0.2148,  ..., -3.4383, -3.4090, -3.4168],\n",
      "        [-3.3716, -0.1269, -0.2148,  ..., -3.4383, -3.4090, -3.4168],\n",
      "        [-3.3716, -0.1269, -0.2148,  ..., -3.4383, -3.4090, -3.4168],\n",
      "        ...,\n",
      "        [-3.3716, -0.1269, -0.2148,  ..., -3.4383, -3.4090, -3.4168],\n",
      "        [-3.3716, -0.1269, -0.2148,  ..., -3.4383, -3.4090, -3.4168],\n",
      "        [-3.3716, -0.1269, -0.2148,  ..., -3.4383, -3.4090, -3.4168]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.4033, -0.1292, -0.2159,  ..., -3.4700, -3.4407, -3.4486],\n",
      "        [-3.4033, -0.1292, -0.2159,  ..., -3.4700, -3.4407, -3.4486],\n",
      "        [-3.4033, -0.1292, -0.2159,  ..., -3.4700, -3.4407, -3.4486],\n",
      "        ...,\n",
      "        [-3.4033, -0.1292, -0.2159,  ..., -3.4700, -3.4407, -3.4486],\n",
      "        [-3.4033, -0.1292, -0.2159,  ..., -3.4700, -3.4407, -3.4486],\n",
      "        [-3.4033, -0.1292, -0.2159,  ..., -3.4700, -3.4407, -3.4486]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.4342, -0.1321, -0.2174,  ..., -3.5009, -3.4716, -3.4794],\n",
      "        [-3.4342, -0.1321, -0.2174,  ..., -3.5009, -3.4716, -3.4794],\n",
      "        [-3.4342, -0.1321, -0.2174,  ..., -3.5009, -3.4716, -3.4794],\n",
      "        ...,\n",
      "        [-3.4342, -0.1321, -0.2174,  ..., -3.5009, -3.4716, -3.4794],\n",
      "        [-3.4342, -0.1321, -0.2174,  ..., -3.5009, -3.4716, -3.4794],\n",
      "        [-3.4342, -0.1321, -0.2174,  ..., -3.5009, -3.4716, -3.4794]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.4643, -0.1355, -0.2195,  ..., -3.5309, -3.5016, -3.5095],\n",
      "        [-3.4643, -0.1355, -0.2195,  ..., -3.5309, -3.5016, -3.5095],\n",
      "        [-3.4643, -0.1355, -0.2195,  ..., -3.5309, -3.5016, -3.5095],\n",
      "        ...,\n",
      "        [-3.4643, -0.1355, -0.2195,  ..., -3.5309, -3.5016, -3.5095],\n",
      "        [-3.4643, -0.1355, -0.2195,  ..., -3.5309, -3.5016, -3.5095],\n",
      "        [-3.4643, -0.1355, -0.2195,  ..., -3.5309, -3.5016, -3.5095]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.4935, -0.1394, -0.2221,  ..., -3.5601, -3.5308, -3.5387],\n",
      "        [-3.4935, -0.1394, -0.2221,  ..., -3.5601, -3.5308, -3.5387],\n",
      "        [-3.4935, -0.1394, -0.2221,  ..., -3.5601, -3.5308, -3.5387],\n",
      "        ...,\n",
      "        [-3.4935, -0.1394, -0.2221,  ..., -3.5601, -3.5308, -3.5387],\n",
      "        [-3.4935, -0.1394, -0.2221,  ..., -3.5601, -3.5308, -3.5387],\n",
      "        [-3.4935, -0.1394, -0.2221,  ..., -3.5601, -3.5308, -3.5387]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.5220, -0.1438, -0.2250,  ..., -3.5886, -3.5593, -3.5672],\n",
      "        [-3.5220, -0.1438, -0.2250,  ..., -3.5886, -3.5593, -3.5672],\n",
      "        [-3.5220, -0.1438, -0.2250,  ..., -3.5886, -3.5593, -3.5672],\n",
      "        ...,\n",
      "        [-3.5220, -0.1438, -0.2250,  ..., -3.5886, -3.5593, -3.5672],\n",
      "        [-3.5220, -0.1438, -0.2250,  ..., -3.5886, -3.5593, -3.5672],\n",
      "        [-3.5220, -0.1438, -0.2250,  ..., -3.5886, -3.5593, -3.5672]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.5498, -0.1485, -0.2284,  ..., -3.6164, -3.5870, -3.5950],\n",
      "        [-3.5498, -0.1485, -0.2284,  ..., -3.6164, -3.5870, -3.5950],\n",
      "        [-3.5498, -0.1485, -0.2284,  ..., -3.6164, -3.5870, -3.5950],\n",
      "        ...,\n",
      "        [-3.5498, -0.1485, -0.2284,  ..., -3.6164, -3.5870, -3.5950],\n",
      "        [-3.5498, -0.1485, -0.2284,  ..., -3.6164, -3.5870, -3.5950],\n",
      "        [-3.5498, -0.1485, -0.2284,  ..., -3.6164, -3.5870, -3.5950]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.5769, -0.1537, -0.2320,  ..., -3.6434, -3.6141, -3.6221],\n",
      "        [-3.5769, -0.1537, -0.2320,  ..., -3.6434, -3.6141, -3.6221],\n",
      "        [-3.5769, -0.1537, -0.2320,  ..., -3.6434, -3.6141, -3.6221],\n",
      "        ...,\n",
      "        [-3.5769, -0.1537, -0.2320,  ..., -3.6434, -3.6141, -3.6221],\n",
      "        [-3.5769, -0.1537, -0.2320,  ..., -3.6434, -3.6141, -3.6221],\n",
      "        [-3.5769, -0.1537, -0.2320,  ..., -3.6434, -3.6141, -3.6221]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.6034, -0.1592, -0.2361,  ..., -3.6698, -3.6405, -3.6485],\n",
      "        [-3.6034, -0.1592, -0.2361,  ..., -3.6698, -3.6405, -3.6485],\n",
      "        [-3.6034, -0.1592, -0.2361,  ..., -3.6698, -3.6405, -3.6485],\n",
      "        ...,\n",
      "        [-3.6034, -0.1592, -0.2361,  ..., -3.6698, -3.6405, -3.6485],\n",
      "        [-3.6034, -0.1592, -0.2361,  ..., -3.6698, -3.6405, -3.6485],\n",
      "        [-3.6034, -0.1592, -0.2361,  ..., -3.6698, -3.6405, -3.6485]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.6292, -0.1650, -0.2404,  ..., -3.6956, -3.6663, -3.6743],\n",
      "        [-3.6292, -0.1650, -0.2404,  ..., -3.6956, -3.6663, -3.6743],\n",
      "        [-3.6292, -0.1650, -0.2404,  ..., -3.6956, -3.6663, -3.6743],\n",
      "        ...,\n",
      "        [-3.6292, -0.1650, -0.2404,  ..., -3.6956, -3.6663, -3.6743],\n",
      "        [-3.6292, -0.1650, -0.2404,  ..., -3.6956, -3.6663, -3.6743],\n",
      "        [-3.6292, -0.1650, -0.2404,  ..., -3.6956, -3.6663, -3.6743]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.6544, -0.1710, -0.2449,  ..., -3.7208, -3.6915, -3.6995],\n",
      "        [-3.6544, -0.1710, -0.2449,  ..., -3.7208, -3.6915, -3.6995],\n",
      "        [-3.6544, -0.1710, -0.2449,  ..., -3.7208, -3.6915, -3.6995],\n",
      "        ...,\n",
      "        [-3.6544, -0.1710, -0.2449,  ..., -3.7208, -3.6915, -3.6995],\n",
      "        [-3.6544, -0.1710, -0.2449,  ..., -3.7208, -3.6915, -3.6995],\n",
      "        [-3.6544, -0.1710, -0.2449,  ..., -3.7208, -3.6915, -3.6995]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.6791, -0.1774, -0.2498,  ..., -3.7454, -3.7161, -3.7241],\n",
      "        [-3.6791, -0.1774, -0.2498,  ..., -3.7454, -3.7161, -3.7241],\n",
      "        [-3.6791, -0.1774, -0.2498,  ..., -3.7454, -3.7161, -3.7241],\n",
      "        ...,\n",
      "        [-3.6791, -0.1774, -0.2498,  ..., -3.7454, -3.7161, -3.7241],\n",
      "        [-3.6791, -0.1774, -0.2498,  ..., -3.7454, -3.7161, -3.7241],\n",
      "        [-3.6791, -0.1774, -0.2498,  ..., -3.7454, -3.7161, -3.7241]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.7032, -0.1840, -0.2548,  ..., -3.7695, -3.7401, -3.7482],\n",
      "        [-3.7032, -0.1840, -0.2548,  ..., -3.7695, -3.7401, -3.7482],\n",
      "        [-3.7032, -0.1840, -0.2548,  ..., -3.7695, -3.7401, -3.7482],\n",
      "        ...,\n",
      "        [-3.7032, -0.1840, -0.2548,  ..., -3.7695, -3.7401, -3.7482],\n",
      "        [-3.7032, -0.1840, -0.2548,  ..., -3.7695, -3.7401, -3.7482],\n",
      "        [-3.7032, -0.1840, -0.2548,  ..., -3.7695, -3.7401, -3.7482]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.7267, -0.1908, -0.2601,  ..., -3.7930, -3.7637, -3.7717],\n",
      "        [-3.7267, -0.1908, -0.2601,  ..., -3.7930, -3.7637, -3.7717],\n",
      "        [-3.7267, -0.1908, -0.2601,  ..., -3.7930, -3.7637, -3.7717],\n",
      "        ...,\n",
      "        [-3.7267, -0.1908, -0.2601,  ..., -3.7930, -3.7637, -3.7717],\n",
      "        [-3.7267, -0.1908, -0.2601,  ..., -3.7930, -3.7637, -3.7717],\n",
      "        [-3.7267, -0.1908, -0.2601,  ..., -3.7930, -3.7637, -3.7717]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.7498, -0.1978, -0.2656,  ..., -3.8161, -3.7867, -3.7948],\n",
      "        [-3.7498, -0.1978, -0.2656,  ..., -3.8161, -3.7867, -3.7948],\n",
      "        [-3.7498, -0.1978, -0.2656,  ..., -3.8161, -3.7867, -3.7948],\n",
      "        ...,\n",
      "        [-3.7498, -0.1978, -0.2656,  ..., -3.8161, -3.7867, -3.7948],\n",
      "        [-3.7498, -0.1978, -0.2656,  ..., -3.8161, -3.7867, -3.7948],\n",
      "        [-3.7498, -0.1978, -0.2656,  ..., -3.8161, -3.7867, -3.7948]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.7724, -0.2050, -0.2712,  ..., -3.8386, -3.8093, -3.8174],\n",
      "        [-3.7724, -0.2050, -0.2712,  ..., -3.8386, -3.8093, -3.8174],\n",
      "        [-3.7724, -0.2050, -0.2712,  ..., -3.8386, -3.8093, -3.8174],\n",
      "        ...,\n",
      "        [-3.7724, -0.2050, -0.2712,  ..., -3.8386, -3.8093, -3.8174],\n",
      "        [-3.7724, -0.2050, -0.2712,  ..., -3.8386, -3.8093, -3.8174],\n",
      "        [-3.7724, -0.2050, -0.2712,  ..., -3.8386, -3.8093, -3.8174]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7946, -0.2124, -0.2770,  ..., -3.8607, -3.8314, -3.8395],\n",
      "        [-3.7946, -0.2124, -0.2770,  ..., -3.8607, -3.8314, -3.8395],\n",
      "        [-3.7946, -0.2124, -0.2770,  ..., -3.8607, -3.8314, -3.8395],\n",
      "        ...,\n",
      "        [-3.7946, -0.2124, -0.2770,  ..., -3.8607, -3.8314, -3.8395],\n",
      "        [-3.7946, -0.2124, -0.2770,  ..., -3.8607, -3.8314, -3.8395],\n",
      "        [-3.7946, -0.2124, -0.2770,  ..., -3.8607, -3.8314, -3.8395]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.8163, -0.2199, -0.2830,  ..., -3.8824, -3.8531, -3.8612],\n",
      "        [-3.8163, -0.2199, -0.2830,  ..., -3.8824, -3.8531, -3.8612],\n",
      "        [-3.8163, -0.2199, -0.2830,  ..., -3.8824, -3.8531, -3.8612],\n",
      "        ...,\n",
      "        [-3.8163, -0.2199, -0.2830,  ..., -3.8824, -3.8531, -3.8612],\n",
      "        [-3.8163, -0.2199, -0.2830,  ..., -3.8824, -3.8531, -3.8612],\n",
      "        [-3.8163, -0.2199, -0.2830,  ..., -3.8824, -3.8531, -3.8612]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.8376, -0.2276, -0.2891,  ..., -3.9037, -3.8744, -3.8825],\n",
      "        [-3.8376, -0.2276, -0.2891,  ..., -3.9037, -3.8744, -3.8825],\n",
      "        [-3.8376, -0.2276, -0.2891,  ..., -3.9037, -3.8744, -3.8825],\n",
      "        ...,\n",
      "        [-3.8376, -0.2276, -0.2891,  ..., -3.9037, -3.8744, -3.8825],\n",
      "        [-3.8376, -0.2276, -0.2891,  ..., -3.9037, -3.8744, -3.8825],\n",
      "        [-3.8376, -0.2276, -0.2891,  ..., -3.9037, -3.8744, -3.8825]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.8585, -0.2354, -0.2953,  ..., -3.9246, -3.8952, -3.9034],\n",
      "        [-3.8585, -0.2354, -0.2953,  ..., -3.9246, -3.8952, -3.9034],\n",
      "        [-3.8585, -0.2354, -0.2953,  ..., -3.9246, -3.8952, -3.9034],\n",
      "        ...,\n",
      "        [-3.8585, -0.2354, -0.2953,  ..., -3.9246, -3.8952, -3.9034],\n",
      "        [-3.8585, -0.2354, -0.2953,  ..., -3.9246, -3.8952, -3.9034],\n",
      "        [-3.8585, -0.2354, -0.2953,  ..., -3.9246, -3.8952, -3.9034]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.8790, -0.2433, -0.3017,  ..., -3.9451, -3.9157, -3.9239],\n",
      "        [-3.8790, -0.2433, -0.3017,  ..., -3.9451, -3.9157, -3.9239],\n",
      "        [-3.8790, -0.2433, -0.3017,  ..., -3.9451, -3.9157, -3.9239],\n",
      "        ...,\n",
      "        [-3.8790, -0.2433, -0.3017,  ..., -3.9451, -3.9157, -3.9239],\n",
      "        [-3.8790, -0.2433, -0.3017,  ..., -3.9451, -3.9157, -3.9239],\n",
      "        [-3.8790, -0.2433, -0.3017,  ..., -3.9451, -3.9157, -3.9239]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.8992, -0.2514, -0.3081,  ..., -3.9652, -3.9359, -3.9440],\n",
      "        [-3.8992, -0.2514, -0.3081,  ..., -3.9652, -3.9359, -3.9440],\n",
      "        [-3.8992, -0.2514, -0.3081,  ..., -3.9652, -3.9359, -3.9440],\n",
      "        ...,\n",
      "        [-3.8992, -0.2514, -0.3081,  ..., -3.9652, -3.9359, -3.9440],\n",
      "        [-3.8992, -0.2514, -0.3081,  ..., -3.9652, -3.9359, -3.9440],\n",
      "        [-3.8992, -0.2514, -0.3081,  ..., -3.9652, -3.9359, -3.9440]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.9190, -0.2595, -0.3147,  ..., -3.9850, -3.9557, -3.9638],\n",
      "        [-3.9190, -0.2595, -0.3147,  ..., -3.9850, -3.9557, -3.9638],\n",
      "        [-3.9190, -0.2595, -0.3147,  ..., -3.9850, -3.9557, -3.9638],\n",
      "        ...,\n",
      "        [-3.9190, -0.2595, -0.3147,  ..., -3.9850, -3.9557, -3.9638],\n",
      "        [-3.9190, -0.2595, -0.3147,  ..., -3.9850, -3.9557, -3.9638],\n",
      "        [-3.9190, -0.2595, -0.3147,  ..., -3.9850, -3.9557, -3.9638]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 159 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ae515dcef504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_loss_at_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_avg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-a9c84d0cb443>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, withCustomLoss)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 159 is out of bounds."
     ]
    }
   ],
   "source": [
    "training_loss, training_acc, min_loss_at_epoch, min_avg_loss = train(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
